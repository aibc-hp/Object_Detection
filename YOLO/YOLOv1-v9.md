# YOLO 系列

YOLO 系列算法的基本原理是将目标检测任务转化为一个回归问题，通过单次前向传播既可预测出图像中的目标位置和类别。

YOLO 系列算法的基本原理：

1. 将一张图片分成 $S*S$ 个区域
2. 每一个区域负责检测中心落在该区域内的物体
3. 每个检测到的物体会产生多个可能的边界框，每个边界框会有一个对应的置信度
4. 每个边界框还会预测属于各个类别的条件概率
5. 利用非极大值抑制保留一个最佳的检测框

在结构上，YOLO 系列模型由以下部分组成：

- input — 模型的输入，用于接收原始图像数据，并对其做一定预处理
- backbone — 模型的主干网络，用于提取图像特征
- neck — 模型的颈部网络，用于对主干网络输出的特征图做相应处理，以增强目标检测能力
- head — 模型的头部网络，通常包括分类器、边界框回归器和置信度估计器，用于预测目标的类别、位置和置信度

## YOLOv1

Joseph Redmon, You Only Look Once: Unified, Real-Time Object Detection, publication date 2015/06

原始图像被划分为 $S*S$ 个单元格，每个单元格预测 $B$ 个边界框，每个边界框有对应的置信度和属于各个类别的概率。因此，在一次前向中，模型会预测 $S*S*B$ 个边界框。置信度为预测框和真实框之间的 $IoU$，如果单元格中没有目标物体，则置信度为零。每个单元格仅预测一组类别，而不考虑边界框的数量。

### Input

YOLOv1 的输入为 $448*448$ 的原始图像，最终得到 $7*7$ 的特征图。

### Backbone

YOLOv1 的主干网络是一个基于 GoogLeNet 的卷积神经网络（CNN），由 24 个卷积层和 2 个全连接层组成。该主干网络的灵感来源于 GoogLeNet，但进行了简化和修改以适应目标检测任务。YOLOv1 的 backbone 使用了 Leaky ReLU 激活函数。 

### Neck

在 YOLOv1 中，并没有明确称之为“颈部网络”的部分。 

### Head

YOLOv1 的输出头部是由全连接层和 $1*1$ 卷积层组成的，用于从提取的特征中预测边界框和类别概率。具体来说，对于每个格子，YOLOv1 预测 $B$ 个边界框（每个边界框由 5 个值表示：中心坐标(x, y)、宽度(w)、高度(h)、置信度(c)），以及每个边界框对应 $C$ 个类别的条件概率。

YOLOv1 的输出是一个 $7*7*30$ 的张量，$7*7$ 是最后一个网络层输出的特征图大小，每一个 grid cell 的通道维数为 $30=2*5+20$，意味着特征图中的每个网格能预测 2 个边界框，每个边界框包含 5 个预测值，再加上 20 个类别。 

### Others

神经网络结构确定之后，模型训练效果的好坏由损失函数和优化器决定。YOLOv1 中使用普通的梯度下降法作为优化器。损失函数由中心点损失、宽高损失、置信度损失、类别损失几部分组成。

YOLOv1 中每个网格预测 2 个边界框，并让最佳的检测框与 ground-truth 进行回归修正。

### Pros and Cons 

优点：

- **实时性较好：** YOLOv1 能够实现快速的目标检测，运行速度超过 45fps，这使得它非常适合需要实时反馈的应用场景
- **简化流程：** 相比于其他需要提取候选区域（Region Proposal Network, RPN）的检测方法，YOLOv1 直接在图像上预测边界框和类别，简化了整个检测流程
- **全局信息利用：** 由于 YOLOv1 是基于整张图片进行预测，因此它可以更好地利用全局上下文信息，减少背景错误
- **泛化能力强：** YOLOv1 学习到的是目标的泛化表示，因此在不同领域或输入中具有较好的适应性，比当时的其他检测器具有更好的泛化性能

缺点：

- **定位精度不高：** YOLOv1 在目标定位精度上不如基于候选区域的方法，尤其是对于尺寸较小的目标 
- **对小目标检测效果不佳：** 由于多次下采样导致特征图分辨率较低，YOLOv1 对小目标的检测能力受到影响
- **预测数量受限：** 由于每个单元格只预测两个边界框和一个类别，这就限制了能预测重叠或邻近物体的数量，比如说两个物体的中心点都落在这个单元格中，但是这个单元格只能预测一个类别
- **损失函数设计有缺陷：** YOLOv1 损失函数的设计存在缺陷，它对大框和小框的错误具有相同的惩罚，这可能导致较大的定位误差，尤其是对于不同尺寸大小的物体；作者试图通过取根来补偿这种影响，但并不能完全消除

### QA

**为什么选用奇数划分单元格？**
答：选用奇数来划分单元格，能够明确中心单元格、简化预测过程、提高小目标物体检测精度。使用奇数尺寸的网格可以保证每个物体的中心点只落在一个特定的单元格内，这样该单元格就负责预测该物体的边界框。如果使用偶数尺寸，一些物体的中心可能会位于两个单元格的边界上，这会导致责任归属不明确。奇数尺寸的网格有助于提高小物体的检测精度，因为这些小物体更容易被完全包含在一个单元格内，而不是跨越多个单元格。  

**为什么损失函数中要有 $\lambda_{coord}$ 和 $\lambda_{noobj}$ 因子？**
答：YOLO 面临的物体检测问题，是一个典型的类别数目不均衡的问题。图像被划分成 49 个格点，含有物体的格点往往只有寥寥几个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的 mAP 不会太高，因为模型更倾向于不含有物体的格点。$\lambda_{coord}$ 和 $\lambda_{noobj}$ 的作用就是让含有物体的格点在损失函数中的权重占比更大，让模型更加重视含有物体的格点所造成的损失。在论文中，$\lambda_{coord}$ 和 $\lambda_{noobj}$ 的取值分别为 5 和 0.5。   

**为什么在预测边界框中心坐标时，不直接回归其坐标，而是回归 offset？**
答：（x, y）不直接回归预测框中心点坐标值，而是回归相对于格点左上角坐标的位移值。例如，第一个格点中物体坐标为（2.3, 3.6），另一个格点中的物体坐标为（5.4, 6.3），这四个数值让神经网络暴力回归，有一定难度。所以这里的 offset 是指，既然格点已知，那么物体中心点的坐标一定在这个格点正方形里，相对于格点左上角的位移值一定在区间 [0, 1) 中。让神经网络去预测（0.3, 0.6）与（0.4, 0.3）会更加容易，在使用时，再加上格点左上角坐标（2, 3）、（5, 6）即可。

**为什么在推理时，将 $p*c$ 作为输出的置信度？**
答：在推理时，使用物体的类别预测最大值 $p$ 乘以预测框的最大值 $c$，作为输出预测物体的置信度。这种设置结合了空间位置和类别信息，同时考虑了边界框的预测质量和类别预测的确定性。这意味着，即使一个边界框的预测很准确（高 $c$），但如果模型对它属于某个类别不是很确定（低 $p$），则整体的置信度也不会很高。这种方法鼓励模型不仅要正确地定位边界框，还要准确地识别出边界框内的类别。而且，还有助于在后续的非极大值抑制（NMS）步骤中筛选出更准确的检测结果。    

## YOLOv2

Joseph Redmon, YOLO9000: Better, Faster, Stronger, publication date 2016/12

### Input

YOLOv2 的输入为 $416*416$ 的原始图像，以得到 $13*13$ 的特征图。

YOLOv2 在输入端引入了多尺度训练，并优化了预训练模型。由于 YOLOv2 网络的下采样倍数为 32，因此输入的不同尺度的图像大小都是 32 的倍数。

### Backbone

YOLOv2 的主干网络是 Darknet-19，它包含 19 个卷积层和 5 个最大池化层。Darknet-19 受到了 GoogLeNet 架构的启发，使用 $1*1$ 卷积层来减少特征图数量，使得参数数量相对较低。此外，YOLOv2 在所有卷积层中引入了批量归一化（Batch Normalization, BN），以加速训练并提高模型的泛化能力。

### Neck

在 YOLOv2 中，并没有明确称之为“颈部网络”的部分。

### Head

YOLOv2 的输出头部由卷积层组成，用于预测边界框坐标、置信度和类别概率。与 YOLOv1 相比，YOLOv2 在每个单元格中预测更多的边界框。与 YOLOv1 一样，YOLOv2 的输出是一个包含了边界框坐标、置信度和类别概率的多维张量。

YOLOv2 不对检测框的宽高直接进行回归，而是将检测框与锚框的偏差（offset）进行回归，每个网格有 $5$ 个 anchor box。在训练时，只有最接近 ground-truth 的检测框进行损失计算。在引入 anchor box 后，mAP 由 69.5 下降至 69.2，原因在于每个网格预测的物体变多之后，召回率大幅上升，准确率有所下降，总体 mAP 略有下降。 

### Others

**偏移量计算**

- $t_x=G_x - C_x$
- $t_y=G_y - C_y$
- $t_w=log(G_w/P_w)$
- $t_h=log(G_h/P_h)$

$(G_x, G_y, G_w, G_h)$ 是 ground-truth 映射到特征图上的框位置，$(C_x, C_y)$ 是特征图上 grid cell 的左上角坐标，$(P_w, P_h)$ 是 Anchor box 映射到特征图上的宽高。从计算公式可以看出，偏移量与锚框的中心坐标无关，只与锚框的宽高有关。

**预测边界框计算**

- $b_x=\sigma (t_x) + C_x$
- $b_y=\sigma (t_y) + C_y$
- $b_w=P_we^{t_w}$
- $b_h=P_he^{t_h}$

### Improve

YOLOv2 相较于 YOLOv1 作了不少改进，这些改进使得 YOLOv2 在保持实时性能的同时，显著提高了目标检测的准确性和鲁棒性，改进如下：

1. **批量归一化（Batch Normalization）：** YOLOv2 在所有卷积层中引入了批量归一化，并去除了 Dropout，这有助于加快学习速度，提高模型的泛化能力，并减少对初始化和学习率选择的敏感性
2. **锚框（Anchor Boxes）：** YOLOv2 引入了锚框，这是一组预定义的边界框，用于匹配不同大小和宽高比的目标。每个单元格预测多个边界框，每个边界框与一个或多个锚框相关联，这提高了对不同尺寸目标的检测能力；在 Faster R-CNN 中，锚框都是事先设定好的，而在 YOLOv2 中，锚框的尺寸不通过人工设定，而是将训练数据集中的矩形框全部拿出来，通过 K-Means 聚类得到先验框的宽和高
3. **高分辨率分类器：** YOLOv2 使用高分辨率的图像进行分类器的训练。在预训练阶段，模型使用 $224*224$ 的 ImageNet 图像，然后在 $448*448$ 的高分辨率图像上进行微调（训练了 10 个 epoch），以提高模型对高分辨率输入的性能
4. **完全卷积架构：** YOLOv2 移除了 YOLOv1 中的全连接层，采用了完全卷积的架构，这使得模型可以处理不同尺寸的输入图像
5. **直接位置预测：** YOLOv2 不像 YOLOv1 那样直接预测边界框的坐标，而是预测相对于先验框的偏移量，通过学习偏移量，就可以依据网络原定的 Anchor box 坐标通过线性回归微调去逐渐靠近 GT 框。YOLOv2 借鉴了 Faster R-CNN 中的先验框方法，改进了边界框的位置预测，与 YOLOv1 相比，YOLOv2 中每个检测框输出 5 个偏差参数 $(t_x, t_y, t_w, t_h, t_o)$，为了将检测框的中心点约束在当前 grid cell 中，使用 sigmoid 函数对 $(t_x, t_y)$ 进行归一化处理，将它们约束在 [0, 1] 之间，这使得模型训练更稳定
6. **细粒度特征：** 当 $26*26$ 的特征图经过卷积和池化变为 $13*13$ 的特征图后，作者认为损失了很多的细粒度特征，导致对小尺寸物体的识别效果不佳，所以在此处加入了 passthrough 层。将 $26*26*1$ 的特征图变成 $13*13*4$ 的特征图，在这一操作中不损失细粒度特征  
7. **多尺度训练：** 由于模型只有卷积和池化，因此对于网络的输入大小没有限制。YOLOv2 使用不同尺寸的输入图像进行训练，具体来说就是在每 10 个 batch 之后，就将图片 resize 成 {320, 352, …, 608} 中的一种。不同的输入会造成产生的格点数不同，比如输入图片的尺寸为 $320*320$，那么输出格点为 $10*10$，如果每个格点的先验框个数设置为 5，那么总共输出 500 个预测结果；如果输入图片大小为 $608*608$，那么输出格点就为 $19*19$，共 1805 个预测结果
8. **网络架构：** 使用 Darknet-19 作为新的网络架构，该架构的网络参数相较于 YOLOv1 的更少，因此速度更快
9. **检测与分类联合训练：** YOLOv2 提出了一种联合训练算法，该算法允许同时在检测数据集和分类数据集上训练物体检测器，也就是说，YOLOv2 中物体的矩形框生成不依赖于物体类别预测，二者独立同时进行。当输入的是检测数据集时，标注信息包含物体的类别和位置，那么对整个 loss 函数进行计算，进行反向传播；当输入图片只包含分类信息时，loss 函数只计算分类部分，其余部分 loss 为零
10. **WordTree：** 联合训练扩充了识别物体的种类，但是类别之间不一定是互斥关系，还可能是包含、相交等关系，该怎么对类别进行预测和训练呢？作者使用 WordTree 解决了这一问题。在类别中，不对所有的类别进行 softmax 操作，而是对同一层级的类别进行 softmax，只有一个类别预测分值最大。在预测时，从树的根节点开始向下检索，每次选取预测分值最高的子节点，直到所有选择的节点预测分值连乘后小于某一阈值时停止。在训练时，如果标签为人，那么只对人这个节点以及其所有的父节点进行 loss 计算，而其子节点如男人、女人、小孩等，不进行 loss 计算 
11. **损失函数改进：** YOLOv2 对损失函数进行了改进，去掉了 YOLOv1 中开根号的操作，用了一个表达式替代，使得尺度较小的预测框的权重系数更大一些，起到了与开根号相似的效果；此外，还添加了一个新的损失计算，用于训练前期（iter < 12800），以促进网络学习到 anchor 的形状

### Pros and Cons

优点：

- **更好的准确率：** 引入了批量归一化、锚框、高分辨率分类器、细粒度特征和多尺度训练等技术，提高了模型的定位准确度和召回率 
- **更快的速度：** 通过新的网络架构，能够在保持较高准确率的同时实现更快的检测速度
- **多尺度检测：** YOLOv2 通过多尺度训练，能够适应不同尺寸的输入图像，使得模型在不同分辨率下都能取得良好的检测效果
- **小目标检测能力提升：** 通过锚框、细粒度特征、多尺度训练等技术，YOLOv2 能够结合高分辨率和低分辨率的特征图，提高了对小目标的检测能力
- **识别种类多：** 通过联合训练和分层分类，YOLOv2 能够识别超过 9000 种物体  

缺点：

- **对重叠和密集目标的处理能力有限：** YOLOv2 虽然提高了召回率，但在处理重叠和密集目标时，仍然存在一定的局限性，容易出现目标漏检或误检的情况 

### QA

**为什么要在卷积层中引入 BN？**

- 加速收敛：通过在每个批次的数据上进行归一化，BN 可以减少梯度消失和梯度爆炸的问题，使得训练过程中的梯度分布更加稳定，网络更容易学习到有效的特征表示，从而加快模型的收敛速度
- 缓解梯度消失：在深层网络中，梯度消失是一个常见的问题，导致深层网络难以训练。BN 通过减少内部协变量偏移（Internal Covariate Shift），即每一层输入的分布变化，从而缓解了梯度消失问题，使得网络更容易训练 
- 允许使用更高的学习率：由于 BN 减少了梯度消失的问题，使得梯度分布更加稳定，因此可以使用更高的学习率来训练网络，而不会导致训练不稳定
- 降低对初始参数的敏感性：BN 使得网络对初始参数（如学习率和初始化权重）的选择不那么敏感
- 正则化效果：BN 通过在每个批次的数据上计算均值和方差来进行归一化，引入了一定的噪声，这可以视为一种正则化形式，有助于防止过拟合，提高模型的泛化能力   

**为什么引入 Anchor Box 替换全连接层？**
答：全连接层可能会导致空间信息的丢失，因为全连接层通常需要将数据展平。在 YOLOv2 中，通过使用卷积层和 Anchor Box，可以保持更多的空间结构信息，从而提高定位精度。相比于全连接层，卷积层可以更高效地利用硬件加速，减少计算量和内存消耗。Anchor Box 使得 YOLOv2 能够在不同尺度上预测边界框，这对于检测不同大小的目标非常有用，提高了模型的鲁棒性。

**为什么在边界框预测中对 $(t_x, t_y)$ 使用 Sigmoid？**
答：使用 Sigmoid 主要目的是将 $(t_x, t_y)$ 压缩到 [0, 1] 区间，可以加速模型在训练前期的收敛。另外，用 Sigmoid 将 $(t_x, t_y)$ 压缩到 [0, 1] 区间，可以有效的确保目标中心处于执行预测的网格单元内，防止偏移过多。如果不对 $(t_x, t_y)$ 进行任何转换，网络可能会预测出超出单元格范围的极端值，这会导致学习过程中出现问题，Sigmoid 函数通过限制输出范围，避免了这种情况。  

**为什么在边界框预测中对 $(t_w, t_h)$ 使用指数？**
答：指数函数可以生成任意正数的输出，这允许模型预测各种宽高的边界框，而不会受到尺寸限制。另外，在计算 $(t_w, t_h)$ 时使用了 log 函数将它们缩放到对数空间，因此需要用指数将它们转换回来。此外，还方便求导。

**为什么在计算偏移量 $(t_w, t_h)$ 时将它们缩放到对数空间？**
答：我的推测是，在对数空间中，不同尺寸的目标分布更加均匀，这有助于模型训练的稳定和收敛。 另外，在训练过程中，对数函数提供了更稳定的梯度，尤其是在物体尺寸变化范围很大时，这有助于避免梯度消失或爆炸问题。 

## YOLOv3

Joseph Redmon, YOLOv3: An Incremental Improvement, publication date 2018/04

### Input

YOLOv3 的输入为 $416*416$ 的原始图像，最后一个卷积层输出的特征图大小为 $13*13$。

### Backbone

YOLOv3 的主干网络是 Darknet-53，该网络引入了大量的残差结构，并使用步长为 2、卷积核大小为 $3*3$ 的卷积层来替代池化层进行下采样。

原始的 Darknet-53 由 52 个卷积层和 1 个全连接层组成，前面的 52 个卷积层用于提取特征，最后一个卷积层后接一个全局平均池化，再接一个有 1000 个神经元的全连接层和一个 Softmax。

在 YOLOv3 中，Darknet-53 只用于提取特征，因此只需前面的 52 个卷积层，而最后的全局平均池化、全连接层和 Softmax 都去除了。

在 YOLOv3 中，最后三个残差块输出的特征图大小分别为 $13*13*1024$、$26*26*512$ 和 $52*52*256$，因此 backbone 最终会输出三种不同尺度的特征图。

### Neck

YOLOv3 的颈部网络用的是特征金字塔网络（Feature Pyramid Network, FPN），FPN 可以将不同尺度的特征图组合成一个特征金字塔，这个特征金字塔可以用于检测图像中不同大小的物体。

backbone 的三个输出分别输入到 FPN 中，$13*13*1024$ 这一输入经过 5 个卷积层后输出 $13*13*512$ 大小的特征图，而后兵分两路，一路传入到 head 中，一路经过一个卷积层和一个上采样得到 $26*26*256$ 大小的特征图。将这个上采样输出和 backbone 的第二个输出进行堆叠（concat），得到 $26*26*768$ 大小的特征图。

$26*26*768$ 经过 5 个卷积层后输出 $26*26*256$ 大小的特征图，而后兵分两路，一路传入到 head 中，一路经过一个卷积层和一个上采样得到 $52*52*128$ 大小的特征图。将这个上采样输出和 backbone 的第三个输出进行堆叠（concat），得到 $52*52*384$ 大小的特征图。

$52*52*384$ 经过 5 个卷积层后输出 $52*52*128$ 大小的特征图，并传入到 head 中。 

最终有三个分支 $13*13*512$、$26*26*256$、$52*52*128$ 传入 head。

### Head

YOLOv3 的头部网络由三个分支组成，每一个分支包含一个 $3*3$ 卷积层和一个 $1*1$ 卷积层。

$13*13*512$ -> Conv $3*3$ -> Conv $1*1$ -> $13*13*75$；

$26*26*256$ -> Conv $3*3$ -> Conv $1*1$ -> $26*26*75$；

$52*52*128$ -> Conv $3*3$ -> Conv $1*1$ -> $52*52*75$；

每个单元格预测 3 个边界框，每个边界框包含 [x, y, w, h, c] 和 20 个类别，$75=3*(4+1+20)$。 

### Others

**多标签分类**

常见的分类形式：

- 二分类（Two-Class Classification），是最简单的分类任务，比如一个任务中只有猫和狗，每个样本中也只有其中的一类
- 单标签分类（Multi-Class Classification），指一个样本（一个图片或者一个检测框）有一个标签，但总共的类别数是大于两类的。目标检测中针对每个检测框的分类是多分类问题。在深度学习中，使用 Softmax 是最常用的解决方案
- 多标签分类（Multi-Label Classification），指一个样本（一个图片或者一个检测框）中含有多个物体或者多个 label。在深度学习中，使用多个 Logistic 输出是一种性价比很高的做法 

YOLOv3 将 YOLOv2 中的单标签分类改进为多标签分类。YOLOv3 在 Head 中，将用于单标签分类的 Softmax 分类器改成了多个独立的用于多标签分类的 Logistic 分类器，取消了类别之间的互斥，可以使网络更加灵活。YOLOv2 使用 Softmax 分类器，认为一个检测框只属于一个类别，每个检测框分配到概率最大的类别，但实际场景中一个检测框可能含有多个物体或者有重叠的类别标签。Logistic 分类器主要用到 Sigmoid 函数，可以将输入约束在 0-1 范围内，当某一检测框的类别置信度经过 Sigmoid 函数约束后，其值大于设定的阈值，就表示该检测框负责检测的物体属于该类别。   

**Anchor 分配**

YOLOv3 在 COCO 数据集上（原始图片全部 resize 为了 $416*416$）聚类了 9 个不同尺寸的 Anchor box，宽高尺寸分别为 $(10*13)$、$(16*30)$、$(33*23)$、$(30*61)$、$(62*45)$、$(59*119)$、$(116*90)$、$(156*198)$、$(373*326)$。YOLOv3 有三个检测头分支，特征图大小分别为 $13*13$、$26*26$、$52*52$，$13*13$ 特征图下采样倍数最大，因此感受野也最大，能看到的目标也是最大的，适合检测较大的目标，故将三种最大尺寸的 Anchor box $(116*90)$、$(156*198)$、$(373*326)$ 分配给此分支；$26*26$ 特征图下采样倍数为 16，感受野中等，适合检测中等大小的目标，故将三种中等尺寸的 Anchor box $(30*61)$、$(62*45)$、$(59*119)$ 分配给此分支；$52*52$ 特征图下采样倍数为 8，感受野最小，适合检测较小的目标，故将三种最小尺寸的 Anchor box $(10*13)$、$(16*30)$、$(33*23)$ 分配给此分支。

**忽略样例**

预测框一共分为三种情况：正例（positive）、负例（negative）、忽略样例（ignore）。

正例：一个 ground-truth 的中心点会分别落在三个分支的特征图中的某个单元格内，三个特征图中对应的单元格负责检测目标。groud-truth 会与每个特征图中的三种锚框计算 IoU，一共会得到 9 个计算值，将最大值的锚框视为正样本。类别标签对应类别为 1，其余为 0；置信度标签为 1。

负例：9 个计算值中，小于阈值（0.5）的锚框为负样本（与 ground-truth 计算 IoU 后，若最大的值也小于阈值，则该最大值的锚框仍为正例）。负样本会参与损失计算，但只计算置信度损失，只产生置信度 loss。置信度标签为 0。

忽略样例：9 个计算值中，大于阈值（0.5），又不是正例的，则为忽略样例。忽略样例不参与损失计算，不产生任何 loss。

**Adam**

Adam 优化器结合了 AdaGrad 和 RMSProp 两种优化算法的优点，对梯度的一阶矩估计（First Moment  Estimation，即梯度的均值）和二阶矩估计（Second Moment  Estimation，即梯度的未中心化的方差）进行了综合考虑，从而计算出更新步长。

Adam 的优点：

1. 实现简单，计算高效，对内存需求少
2. 参数的更新不受梯度的伸缩变换影响
3. 超参数具有很好的解释性，且通常无需调整或仅需很少的微调
4. 更新的步长能够被限制在大致的范围内（初始学习率）
5. 能自然地实现步长退火过程（自动调整学习率）
6. 很适合应用于大规模的数据及参数的场景
7. 适用于不稳定目标函数
8. 适用于梯度稀疏或梯度存在很大噪声的问题

### Improve

YOLOv3 相较于 YOLOv2 作了如下改进：

1. **网络架构：** YOLOv2 使用的是 Darknet-19 作为其主干网络，而 YOLOv3 则使用了更深、更复杂的 Darknet-53 网络。Darknet-53 具有更多的卷积层，且具有残差结构，这使得它能够提取更深层次的特征，从而提高检测的准确性
2. **下采样方式：** YOLOv2 中利用池化层实现网络的下采样，而 YOLOv3 优化了下采样方式，去掉了池化层，直接用卷积层来实现下采样
3. **FPN：** YOLOv3 引入了 FPN 结构，能够将低层次的细节信息和高层次的语义信息结合起来，通过融合不同尺度的特征图，使得模型可以同时检测不同大小的物体
4. **多标签分类：** YOLOv3 将 YOLOv2 中的单标签分类改进为了多标签分类 
5. **损失函数改进：** YOLOv3 对损失函数进行了改进。在 YOLOv2 中，置信度损失和分类损失都使用均方误差来表示，而在 YOLOv3 中，它们都改为了用交叉熵来表示
6. **优化器：** YOLOv2 中使用的优化器是 SGD，而 YOLOv3 论文中没有提及优化器，Adam、SGD 等优化器都可以使用，github 上的 YOLOv3 项目大多使用 Adam 优化器
7. **检测头数量：** YOLOv2 只有一个检测头，只能在一个尺度下检测目标，而 YOLOv3 有三个，可以在不同尺度下进行目标检测，提高了对不同大小物体的检测能力
8. **NMS 改进：** YOLOv3 使用了更加有效的 NMS 方法
9. **Logistic：** 用逻辑回归替代 Softmax 作为分类器，以实现多标签分类
10. **预测框数量：** YOLOv2 中，每个单元格预测 5 个边界框，共预测 $13*13*5=845$ 个边界框；而在 YOLOv3 中，会通过聚类选择 9 个不同尺寸的锚框，对于每个分支的特征图，其上的每个单元格预测 3 个边界框，共预测 $(13*13+26*26+52*52)*3=10647$ 个边界框，是 YOLOv2 的 12 倍

### Pros and Cons

优点：

- 速度快：速度快是 YOLO 系列算法的重要特质，能够很好地平衡精度与速度之间的性能
- 通用性强：能够较好地检测不同大小的物体

缺点：

- 召回率较低，定位精度较差，对密集目标的检测能力较弱

### QA

**为什么要引入残差结构？**

- 梯度传递：在非常深的网络中，信息需要从输入层传递到输出层，梯度在反向传播过程中可能会逐渐消失，导致网络深层的权重难以更新。残差结构允许网络中的信息绕过一些层直接传播，有助于避免梯度消失和梯度爆炸问题
- 网络深度：残差结构允许设计者增加更多的卷积层而不用担心梯度消失问题，这使得 YOLOv3 可以使用更深的 Darknet-53 作为其主干网络，而不会显著影响训练效率
- 特征融合：残差结构通过跳跃连接（skip connections）实现了不同层之间的特征融合，这有助于网络学习到更丰富的特征表示，从而提升检测性能
- 计算效率：残差结构可以在不显著增加计算负担的情况下增加网络的深度，因为每个残差块可以设计成与输入具有相同维度，这意味着额外的层不会增加额外的参数或计算量    

**为什么要用步长为 2 的卷积层来替换池化层进行下采样？**
答：能够减少信息丢失，卷积操作可以学习到如何在下采样的同时保留重要的特征信息，而池化层可能会丢失一些对检测任务有用的细节信息，因为卷积层有可训练的参数，而池化层通常是固定不变的操作。   

**为什么要设置 3 个检测头，能不能设置更多？**
答：不同层级的特征图具有不同的分辨率，较低层次的特征图分辨率较高，具有较小的感受野，适合捕捉细节信息，因此适合检测小目标；而高层次的特征图分辨率较低，具有较大的感受野，适合提取语义信息，因此适合检测大目标。通过多检测头的设定，模型能够更好地检测不同尺度的目标，有助于进一步提升小目标的检测能力。
理论上，可以设置更多的检测头，以获得更好的性能，论文中作者考虑到精度和召回率的平衡，因此选择了三个检测头。增加检测头会存在一些潜在问题，比如每增加一个检测头，都会增加模型的参数数量和计算量，导致更高的计算成本和更慢的检测速度；增加检测头的数量并不总是能够线性提升性能，存在一个性能饱和点，超过这一点，额外的检测头带来的性能提升将非常有限。   

**为什么设置 9 个先验框，能不能设置更多？**
答：不同目标具有不同的尺寸，9 个先验框提供了更多样化的尺寸选择，有助于模型捕捉到不同大小的目标。YOLOv3 的先验框是通过 k-means 聚类方法在 COCO 数据集上得到的，9 个先验框较好地覆盖了该数据集中目标尺寸的分布。
理论上，可以设置更多的先验框，以获得更好的性能，但这也会带来一些问题，比如增加先验框的数量会增加模型的参数和计算量，这可能导致模型训练和推理的速度变慢；性能存在饱和，在某个点上，增加先验框的数量所带来的性能提升会逐渐减少；此外，过多的先验框可能导致模型在训练数据上过拟合，尤其是在数据量不是非常大的情况下。  

## YOLOv4

Alexey Bochkovskiy, YOLOv4: Optimal Speed and Accuracy of Object Detection, publication date 2020/04

### Input

使用了 CutMix 和 Mosaic 数据增强技术，其中 Mosaic 是 YOLOv4 提出的创新技术，从 CutMix 优化而来。

CutMix 使用两张图像分别选取部分像素进行拼接，以产生新的图像数据。而 Mosaic 则在此基础上将图像数量增加到四张，并采用随机缩放、裁剪、排布的方式进行拼接。 

Mosaic 数据增强的实现流程如下：

1. 随机选择四张图片，并为它们分配在 Mosaic 图像中的位置（例如，左上、右上、左下、右下）
2. 对每张图片进行随机缩放和裁剪，以适应它们在 Mosaic 图像中的预定位置
3. 将裁剪后的图片部分放置在 Mosaic 画布的相应位置，可能会有一部分图片超出画布边界，这部分将被舍弃  
4. 对于每张图片中的边界框（bounding boxes），根据它们在 Mosaic 图像中的新位置进行坐标更新  

### Backbone

YOLOv4 的主干网络是 CSPDarknet53，这是一种改进的 Darknet53 网络。YOLOv4 受 CSPNet 网络结构的启发，将多个 CSP（Cross Stage Partial）模块进行组合，通过 CSP 结构减少了计算量，同时保持了较好的特征提取能力。CSPNet 设计的主要目的是在减少计算量的同时实现更丰富的梯度组合。CSP 将基础层的特征映射划分为两部分，然后通过跨阶段层次结构将它们合并，通过这种方式，传播的梯度信息可以具有很大的相关性差异。CSP 模块不仅仅是一个子结构，更是一个处理思想，可以和 ResNet、ResNext、DenseNet、EfficientNet 等网络架构结合使用。

### Neck

YOLOv4 的颈部网络使用了 SPP（Spatial Pyramid Pooling）和 PANet（Path Aggregation Network）结构，这些结构有助于整合不同尺度的特征图，增强模型对不同尺寸目标的检测能力。

SPP 模块在 YOLOv3_SPP.cfg 中率先展现，在 YOLOv4 中成为了一个标配。SPP 模块包含了三个最大池化层，核大小分别为 $5*5$、$9*9$、$13*13$，通过 Padding 操作，使得每个最大池化层输出的特征图大小不变，以便用于 Concat 操作。SPP 模块代替了卷积层后的常规池化层，既可以增大感受野，又能获得多尺度特征，训练速度也能让人接受。Yolov4 使用 $608*608$ 大小的图像在 COCO 检测任务上进行实验，SPP 模块能以 0.5% 的额外计算代价将 AP50 提升 2.7%。

PAN 模块在 FPN 模块的基础上增加了自底向上（信息流）的特征金字塔结构，能够对不同层次的特征进行更好的融合，保留了更多的浅层特征，进一步提升了整体的特征提取能力。 

### Head

YOLOv4 的头部网络沿用了 YOLOv3 的 head，并引入了 CIoU Loss 和 DIoU NMS 来提升整体性能。

在 YOLOv3 中，使用 MSE（均方误差）损失函数对检测框的中心点和宽高进行优化，在 MSE 损失函数的逻辑中，将检测框的中心点和宽高视作独立的变量，但实际上它们之间是有关联的。对于这个问题，一个直观的解决方案是使用 IoU 损失替代 MSE 损失。

在 YOLOv4 论文中，依次提到了 IoU Loss、GIoU Loss、DIoU Loss 和 CIoU Loss，其中 IoU Loss 是基石，也是最为简单的。YOLOv4 使用 CIoU Loss 替代了中心点损失和宽高损失。

YOLOv1-v3 使用传统的 NMS 操作，而 YOLOv4 改进了该操作，使用了 DIoU 思想来计算 NMS 中的 IoU 值，进一步优化了后处理效果。CIoU 思想在训练中有很大作用，但在推理时并没有 ground-truth 信息，因此在 NMS 过程中使用 DIoU 足矣，且能减少计算量。

### Others

**数据增强**

常用的基础数据增强技术：

- 平移变换：向上下左右四个维度移动图像
- 翻转变换：关于水平或竖直的轴进行图像翻转操作
- 裁剪变换：主要有中心裁剪和随机裁剪
- 缩放变换：按比例大小进行图像的放大与缩小
- 颜色变换：在色彩通道空间进行数据增强，比如将某种颜色通道关闭，或者改变亮度值等
- 旋转变换：选择一个角度，左右旋转图像，可以改变图像内容朝向 
- 仿射变换：对图像进行一次线性变换并接上一个平移变换
- 噪声扰动：添加噪声，将高斯分布中采样出的随机值矩阵加入到图像中
- 锐化和模糊：使用高斯算子、拉普拉斯算子等处理图像

常用的高阶数据增强技术：

- 基于生成遮挡：
  - Cutout
  - RandErasing
  - HideAndSeek
  - GridMask 等
- 基于图片混合：
  - Mixup
  - Cutmix
  - Mosaic 等
- 基于搜索（NAS）：
  - AutoAugment
  - FastAutoAugment
  - RandAugment 等
- 基于 GAN：
  - CycleGAN
  - 条件 GAN 等

简单说明一下其中的几种数据增强技术。RandErasing 将图像的部分区域替换为随机值，或者是训练集的平均像素值。GridMask 使用一个网格掩码，并将掩码进行随机翻转，与原图相乘，从而得到增广后的图像，通过超参数控制生成的掩码网格大小。基于 NAS 搜索的 AutoAugment 在一系列图像增强子策略的搜索空间中，通过搜索算法找到适合特定数据集的图像增强方案。针对不同类型的数据集，会包含不同数量的子策略。每个子策略中都包含两种变换，针对每张图像都随机的挑选一个子策略，然后以一定的概率来决定是否执行子策略中的每种变换方法。   

**CutMix**

CutMix 是从 Cutout 和 Mixup 优化而来的。Cutout 是将图片中的部分区域像素值置 0，label 不变。Mixup 是将两张图片按比例混合，其 label 也按同等比例分配。

CutMix 的优点：

- 由于采用填充的形式，合成的图片不会有不自然的混合情形
- 高价值信息增多，提升训练效率，优化算法性能
- 作为 YOLOv4 的 Bag-of-freebies，其不增加模型的推理耗时
- 增加算法的局部识别与局部定位能力
- 在输入侧，起到了类似 dropout 的作用

**Mish**

Mish 激活函数有三个主要特征：

- 无上界有下界。Mish 向上无边界，避免了由于封顶而导致的梯度饱和，能够加快训练过程；向下有边界则有助于实现强正则化效果
- 非单调函数。Mish 允许其在负半轴有稳定的微小负值，从而使梯度流更稳定；与 ReLU 负半轴的硬零边界相比，其梯度更平滑
- 无穷连续性与光滑性。Mish 具有较好的泛化能力，能够提高训练结果的质量   

**IoU Loss 及其变体**

`IoU Loss`

IoU Loss 公式如下：
$$
L_{IoU} = 1 - IoU(A, B) = 1 - \frac{A\cap B}{A\cup B}
$$
其中，A 代表预测框，B 代表真实框，IoU 代表两者的交并比。

IoU Loss 思想简单明了，但存在两个问题：

1. 当预测框和真实框不相交时，IoU 为 0，无法反映两个框的距离远近，进而导致 IoU Loss 不可导
2. 对于一个真实框，当不同的预测框大小相同，且它们与真实框之间的 IoU 也相同时，IoU Loss 无法反映不同预测框之间的位置差异

`GIoU Loss`

针对 IoU Loss 存在的问题，提出了 GIoU Loss，它在预测框与真实框之外构建一个最小外接矩形来缓解 IoU Loss 存在的问题，其公式如下：
$$
L_{GIoU} = 1 - GIoU(A, B) = 1 - IoU(A, B) + \frac{|C - A\cup B|}{|C|}
$$
其中，C 代表最小外接矩形，公式的最后一项代表用差集来约束和惩罚 IoU Loss 对位置信息的不敏感。

GIoU Loss 改进了 IoU Loss 无法反映位置差异的问题，但仍存在以下问题：

1. 当预测框在真实框内部时，最小外接矩形就是真实框，差集的逻辑便失效了，GIoU Loss 退化成了 IoU Loss，此时若存在多个相同大小的预测框，则无法反映它们的相对位置关系

`DIoU Loss`

DIoU Loss 在 GIoU Loss 的基础上提出了中心点距离的概念，来改进 GIoU Loss 被打回原形的问题，其公式如下：
$$
L_{DIoU} = 1 - DIoU(A, B) = 1 - IoU(A, B) + \frac{D_2^2}{D_1^2}
$$
其中，$D_1$ 为最小外接矩形的对角线长度，$D_2$ 为预测框中心点与真实框中心点之间的欧式距离。

DIoU Loss 对预测框和真实框的中心点进行度量，引入位置信息的同时加快了损失函数的收敛。尽管 DIoU Loss 改进了 GIoU Loss，但仍存在以下问题：

1. 假设几个宽高不同但大小相同的预测框都在真实框内，且它们的中心点都在一个地方，那么这个时候中心点距离对预测框宽高的优化就失效了。也就是说，在中心点一致的情况下，DIoU Loss 难以优化不同预测框的宽和高

`CIoU Loss`

CIoU Loss 在 DIoU Loss 的基础上作了进一步改进，将预测框的宽高比考虑了进来，从而将边界框回归损失的三大逻辑（重叠面积、中心点距离、宽高比）进行了有效整合，其公式如下：
$$
L_{CIoU} = 1 - CIoU(A, B) = 1 - IoU(A, B) + \frac{D_2^2}{D_1^2} + \frac{v^2}{1 - IoU(A, B) + v}
$$
其中，v 代表了宽高比一致性的参数 $v=\frac{4}{\pi^2}(arctan\frac{w^{gt}}{h^{gt}} - arctan\frac{w}{h})^2$。

**SAT 及对抗样本**

YOLOv4 中的 SAT（self adversarial training）使用基于 FGSM 原理的梯度攻击技术，生成对抗样本进行对抗训练。对抗样本指的是将生成的扰动噪声添加到原始图像中，以得到更具挑战性的样本。对抗样本容易迷惑模型，使模型输出错误判断，这给模型的鲁棒性造成了很大挑战。因此，在训练时将对抗样本加入到训练集一起训练（对抗训练），可以较好地丰富训练集，使得数据集逼近我们想要的数据分布。经过对抗训练后的模型，其鲁棒性和泛化性都能有较好地提升。

生成对抗样本的方法主要有三类：

- 基于梯度的攻击：FGSM、PGD、AOA 等
- 基于优化的攻击：C&W、DeepFool 等
- 基于 GAN 的攻击：AdvGAN、NaturalGAN 等

### Improve

YOLOv4 相较于 YOLOv3 作了如下改进：

1. **数据增强：** YOLOv4 使用了更复杂的数据增强技术，CutMix + Mosaic
2. **网络架构：** YOLOv4 使用了新的网络架构 CSPDarknet53，能够显著减少计算量
3. **CmBN：** YOLOv4 引入了 CmBN 来替代传统的 BN
4. **DropBlock：** YOLOv4 引入了 DropBlock 正则化技术
5. **Class label smoothing：** YOLOv4 引入了 label smoothing 技巧，它可以看作是一种防止过拟合的正则化方法。它主要是在 one-hot 标签中加入噪声，从而将标签的确定性减弱，以减小训练时损失函数中 ground-truth 的权重，来达到降低过拟合可能性的作用，增强模型的泛化能力
6. **SAT：** YOLOv4 引入了自对抗训练（Self-Adversarial Training, SAT）方法，这是一种新的数据增强技术，旨在通过神经网络自身进行的对抗式攻击，来提高模型的泛化能力和鲁棒性
7. **Mish：** YOLOv4 使用了 Mish 激活函数来替代 Leaky ReLU
8. **SPP：** YOLOv4 引入了 SPP 模块，SPP 通过融合不同大小的最大池化层来获得更鲁棒的特征表示
9. **FPN-PAN：** YOLOv4 引入了 PAN 结构，FPN 层自顶向下可以捕获强语义特征，而 PAN 则通过自底向上传达强定位特征，通过组合这两个模块，可以很好的完成目标定位的功能  
10. **损失函数改进：** 对损失函数进行了改进，提高了小目标的检测性能
11. **CIoU：** 在进行 loss 计算时，YOLOv4 使用了 CIoU 替代 IoU。CIoU loss 同时考虑了重叠区域、中心点的距离和纵横比，在边界框回归问题上能达到更好的收敛速度和准确率
12. **DIoU-NMS：** YOLOv4 使用了 DIoU-NMS 来改进 NMS
13. **正负样本匹配策略：** YOLOv4 更新了正负样本匹配策略，将在 YOLOv3 中原本会被忽略的样本变为正样本，从而增加了正样本的数量

### QA

**为什么要使用 Mosaic 数据增强技术？**

- 丰富数据集：Mosaic 技术通过随机缩放和裁剪四张图片，然后将它们拼接在一起，大大丰富了检测数据集
- 提高泛化能力和鲁棒性：Mosaic 技术使得图像可以模拟更多样化的场景和背景，从而提高模型对于复杂背景的泛化能力和模型鲁棒性
- 提升小目标检测能力：在拼接过程中，由于图片的随机缩放，可以增加许多小尺寸的目标，有助于提升模型检测小目标的能力
- 改善 BN：在进行批量归一化时，由于一次可以处理多张图片的数据，因此不需要设置很大的 mini-batch size，这有助于模型训练的稳定性
- 减少 GPU 显存使用：由于 Mosaic 一次性处理多张图片，因此可以减少每个 mini-batch 需要处理的图片数量，从而降低 GPU 显存的使用  

**为什么要使用 CmBN 来替代 BN？**
答：BN 指的是对每个小批量（mini-batch）数据的输入进行归一化，使其具有均值为 0 和方差为 1 的分布，这有助于减少内部协变量偏移（Internal Covariate Shift），即网络层输入数据分布的变化，从而允许使用更高的学习率和更少的正则化。
BN 对批次大小比较敏感，批量较小（即样本少）可能导致在该批量中估计的均值和方差不准确，进而影响模型性能。针对这个问题，清华和微软的学者提出了一种交叉迭代批归一化（Cross-Iteration Batch Normalization, CBN）方法。该方法利用多个最近迭代的样本来提高数据估计的质量，但由于在迭代过程中网络权重不断变化，来自不同迭代的网络激活不能相互比较，因此作者提出一种基于泰勒多项式的技术来补偿迭代之间网络权值的变化，从而能够有效利用之前迭代的样本来改进批量归一化。说简单点，CBN 就是一种通过补偿迭代之间网络权值的变化，而有效的利用之前的迭代样本来改进批量归一化的方法。
CBN 主要用来解决在 batch size 较小时，BN 的效果不佳问题。CBN 连续利用多个迭代的数据来变相扩大 batch size，从而改进模型的效果（每次迭代时将包括本次迭代在内的三个迭代作为一个整体，计算整体的 BN）。CBN 将前几次 iteration 的 BN 参数保存起来，当前 iteration 的 BN 参数由当前 batch 数据求出的 BN 参数和保存的前几次的 BN 参数共同推算得出。但这存在一个问题，过去的 BN 参数是由过去的网络参数计算出来的特征得到的，而本轮迭代中计算 BN 时，它们的模型参数其实已经过时了。CmBN（Cross mini-Batch Normalization）是 CBN 的修改版，每个 batch 中的统计不会使用 batch 之前迭代的信息，而是把 batch 内的 4 个 mini-batch 当做一个整体，对外隔离。  

**为什么要引入 DropBlock？**
答：Dropout 被广泛地用作全连接层的正则化技术，但是对于卷积层，通常不太有效。Dropout 在卷积层不 work 的原因可能是由于卷积层的特征图中相邻位置元素在空间上共享语义信息，所以尽管某个单元被 Dropout 掉，但与其相邻的元素依然可以保有该位置的语义信息，信息仍然可以在卷积网络中流通。
针对卷积网络，我们需要使用一种结构化形式的 Dropout 来正则化，即按块丢弃。DropBlock 便是一种结构化形式的 Dropout，它将 feature map 中相邻区域的单元放在一起 drop 掉。除了卷积层外，在跳跃连接中应用 DropbBlock 也可以提高精确度。此外，在训练过程中，逐渐增加 dropped unit 的数量会导致更好的准确性和对超参数选择的鲁棒性。
DropBlock 通过随机丢弃特征图中的连续区域，迫使网络在训练过程中不依赖于单一的特征区域，从而提高模型对于不同特征的泛化能力（提高泛化能力）；由于卷积层中的特征在空间上是相关的，传统的 Dropout 方法可能无法有效地阻止过拟合，DropBlock 通过结构化的方式丢弃特征，可以更有效地处理这一问题（减小过拟合）；DropBlock 并不是简单地将神经元丢弃，而是随机地丢弃特征图中的一部分区域（Block），这种方法能够更好地保留输入数据的结构信息，因为它不会破坏特征图中的相邻关系（保留特征的结构信息）；DropBlock 可以在不需要很大 batch size 的情况下工作，从而减少 GPU 显存的使用（减少 GPU 显存使用）；DropBlock 可以很容易地集成到现有的卷积网络结构中，而不需要对网络架构进行大规模修改（与现有网络结构兼容）。   

**为什么使用 Mish 来替代 Leaky ReLU？**
答：Mish 具备 ReLU 的收敛快速和 Sigmoid 的平滑，在深层模型上的效果优于 ReLU。Mish 具有非单调性，可以让函数在作用的时候依旧保留较小的负值，从而更稳定地提供梯度流。Mish 的平滑性非常好，使其具有较好地泛化能力。 

## YOLOv5

YOLOv5 由 Glenn Jocher 等人研发，是 Ultralytics 公司的开源项目，从 2020/06 发布至今，已更新了多个版本。YOLOv5 只有代码，没有论文，目前有 YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x 四个版本，通过深度（depth）和宽度（width）两个参数控制。YOLOv5s 网络最小，速度最快，AP 精度也最低，随着网络的不断加深加宽，AP 精度也会不断提升，但速度的消耗也在不断增加。

YOLOv5 以其稳定性和易用性深受广大开发者的喜爱，是目前目标检测算法的首选模型之一，在各大芯片平台也有很好的适配性。此外，YOLOv5 还融入了分类、分割、定点等功能，拓宽了其应用场景。

### Input

**Mosaic 数据增强**

YOLOv5 沿用了 Mosaic 数据增强技术，该技术启发于 2019 年底提出的 CutMix 方法（CutMix 用两张图片拼接，Mosaic 用了四张），有助于提升对小目标的检测能力。同时提出了一种自适应锚框计算方法和一种自适应图片缩放方法。

在目标检测中，小目标的 AP 一般比中目标和大目标的低很多，虽然 COCO 数据集中包含了大量的小目标，但这些小目标的分布并不均匀。

COCO 数据集中，小目标的数量占比达到 41.4%，比中目标和大目标的数量都要多。但只有 52.3% 的图片中含有小目标，而图片含中目标和大目标的占比要高得多，分布相对更加均匀。如下表所示：

|                             | Small | Mid  | Large |
| :-------------------------: | :---: | :--: | :---: |
|   Ratio of total boxes(%)   | 41.4  | 34.3 | 24.3  |
| Ratio of images included(%) | 52.3  | 70.7 | 83.0  |

2019 年发布的一篇论文对小、中、大目标作出了定义：

- 小目标：$0*0$ ~ $32*32$
- 中目标：$32*32$ ~ $96*96$
- 大目标：$96*96$ ~ $∞*∞$

**自适应锚框计算**

在 YOLO 系列算法中，针对不同的数据集，都会有预先设定长宽的锚框。在网络训练中，模型会在初始锚框的基础上输出预测框，进而和真实框进行比对，计算两者差距，再通过优化方法反向更新，从而迭代更新网络参数，因此初始锚框是 YOLO 算法中较为重要的一部分。

在 YOLOv3、YOLOv4 中，训练不同的数据集时，计算初始锚框是通过单独的程序运行的。但在 YOLOv5 中将此功能嵌入到了代码中，每次训练将会自适应的计算不同训练集中的最佳锚框值。如果觉得计算的锚框效果不好，可以将自动计算锚框功能关闭。

**自适应图片缩放**

由于原始图像的长宽都不一样，因此会将图像缩放到一个固定尺寸，再送入网络中进行训练和推理。常用的方式是将图像缩放至固定尺寸，并对部分区域进行填充，这里有一个问题，当填充的区域较大时，容易存在信息冗余，从而影响推理速度。因此，在 YOLOv5 中使用了自适应图片缩放方法，以减少冗余的填充。自适应图片缩放方法用于模型的推理，减少了推理时的计算量，提升了推理速度。而在训练时，还是采用了常用的填充方式对图像进行缩放，并没有用自适应图片缩放方法。

### Backbone

在 YOLOv5 中，图片送入 backbone，会先经过一个 Focus 模块，而后再送入 CSPDarknet53 网络。结构与 YOLOv4 基本一致。

Focus 结构主要采用了切片操作，以 YOLOv5s 为例，$608*608*3$ 的原始图像输入到 Focus 结构，而后通过切片操作，先变成 $304*304*12$ 大小的特征图，再用 32 个卷积核进行一次卷积操作，最终变成 $304*304*32$ 大小的特征图。 

值得一提的是，YOLOv5 的前几个版本用了 Focus 结构，但从第六版开始，就舍弃了该结构，取而代之的是 $(6*6, stride=2)$ 的常规卷积，其产生的参数更少，效果更好。

YOLOv5 沿用了 YOLOv4 中的 CSP 结构，但与 YOLOv4 的不同之处在于，YOLOv4 中只有主干网络使用了 CSP 结构，而 YOLOv5 中设计了两种 CSP，一种用于 backbone，一种用于 neck。

### Neck

YOLOv5 沿用了 YOLOv4 的 SPP+PAN neck，不同之处在于，在 YOLOv4 的 neck 中，采用的都是普通卷积操作，而在 YOLOv5 的 neck 中，设计了一种借鉴于 CSPNet 的 CSP 结构，该结构取代了 PAN 中的 CBL 模块，能够增强特征融合的能力。

### Head

YOLOv5 沿用了 YOLOv4 的 head，并在此基础上引入了邻域正负样本分配策略。

由于增加高质量正样本检测框可以显著加速模型收敛，故 YOLOv5 设计了相应的邻域正负样本分配策略，其主要流程如下：

1. 将 ground-truth 与当前分支特征图的 Anchor box 进行比较，如果 ground-truth 与 Anchor box 的宽高比都处在 [1/4, 4]，那么这个 ground-truth 就能与当前分支特征图相匹配
2. 将 ground-truth 分配给对应的 grid cell，而后将这个 grid cell 分为四个象限，并计算 ground-truth 处于四个象限中的哪一个，从而将该象限邻近的两个 grid cell 中的检测框也作为正样本

比起 YOLOv4 中一个 ground-truth 只能匹配一个正样本，YOLOv5 能够在多个 grid cell 中都分配到正样本，有助于正负样本平衡和加速模型收敛。

### Others

**四种网络的参数**

与 YOLOv3、YOLOv4 的 cfg 文件不同，YOLOv5 的四种模型都是以 yaml 的文件格式呈现，而且四个文件的内容基本上都是一样的，只有最上方的 depth_multiple 和 width_multiple 两个参数不同，一个控制网络的深度，一个控制网络的宽度。

|                | YOLOv5s.yaml | YOLOv5m.yaml | YOLOv5l.yaml | YOLOv5x.yaml |
| :------------: | :----------: | :----------: | :----------: | :----------: |
| depth_multiple |     0.33     |     0.67     |     1.0      |     1.33     |
| width_multiple |     0.50     |     0.75     |     1.0      |     1.25     |

**四种网络的深度**

YOLOv5 的四种网络中，每个 CSP 结构的深度（即 CSP 的数量）都是不同的。网络深度的增加，也会增强网络特征提取和特征融合的能力。

|             | YOLOv5s | YOLOv5m | YOLOv5l | YOLOv5x |
| :---------: | :-----: | :-----: | :-----: | :-----: |
| 第一个 CSP1 | CSP1_1  | CSP1_2  | CSP1_3  | CSP1_4  |
| 第二个 CSP1 | CSP1_3  | CSP1_6  | CSP1_9  | CSP1_12 |
| 第三个 CSP1 | CSP1_3  | CSP1_6  | CSP1_9  | CSP1_12 |
| 第一个 CSP2 | CSP2_1  | CSP2_2  | CSP2_3  | CSP2_4  |
| 第二个 CSP2 | CSP2_1  | CSP2_2  | CSP2_3  | CSP2_4  |
| 第三个 CSP2 | CSP2_1  | CSP2_2  | CSP2_3  | CSP2_4  |
| 第四个 CSP2 | CSP2_1  | CSP2_2  | CSP2_3  | CSP2_4  |
| 第五个 CSP2 | CSP2_1  | CSP2_2  | CSP2_3  | CSP2_4  |

CSP1 用于 YOLOv5 的 backbone，CSP2 用于 YOLOv5 的 neck。在第一个 CSP1 中，YOLOv5s 使用了 1 个残差块，因此是 CSP1_1；YOLOv5m 使用了 2 个残差块，因此是 CSP1_2。 

**四种网络的宽度**

YOLOv5 的四种网络在不同阶段的卷积核数量都是不一样的，因此也直接影响特征图的通道数。网络宽度的增加，也会增强网络的特征学习能力。

|            | YOLOv5s(kernels) | YOLOv5m(kernels) | YOLOv5l(kernels) | YOLOv5x(kernels) |
| :--------: | :--------------: | :--------------: | :--------------: | :--------------: |
|   Focus    |        32        |        48        |        64        |        80        |
| 第一个 CBL |        64        |        96        |       128        |       160        |
| 第二个 CBL |       128        |       192        |       256        |       320        |
| 第三个 CBL |       256        |       384        |       512        |       640        |
| 第四个 CBL |       512        |       768        |       1024       |       1280       |

### Improve

YOLOv5 相较于 YOLOv4 作了如下改进：

1. **自适应锚框计算：** YOLOv5 引入了自适应锚框计算方法
2. **自适应图片缩放：** YOLOv5 引入了自适应图片缩放方法，用于模型的推理，以加快推理速
3. **Focus：** YOLOv5 引入了 Focus 模块，通过 Slice 操作，增加信息量，减小参数量和计算量，提升推理速度
4. **CSP：** YOLOv4 只在 backbone 中使用了 CSP 结构，而 YOLOv5 设计了两种 CSP 结构，分别用于 backbone 和 neck
5. **邻域正负样本分配策略：** YOLOv5 引入了基于宽高比的邻域正负样本分配策略，有助于正负样本平衡和加速模型训练
6. **混合精度训练：** YOLOv5 尝试了混合精度训练，其能在尽可能减少精度损失的情况下，利用 FP16 加速训练，并使用 FP16 存储模型权重，在减少内存占用的同时起到了加速训练的效果
7. **模型 EMA 策略：** YOLOv5 尝试了模型 EMA（Exponential Moving Average）策略，对模型近期 epoch 的参数取平均，以提高模型整体检测性能及鲁棒性

## YOLOX

Zheng Ge, YOLOX: Exceeding YOLO Series in 2021, publication date 2021/07

YOLOX 是旷视科技于 2021 年提出的目标检测算法，它基于 YOLOv3-SPP 进行改进，将原有的 anchor-based 改成了 anchor-free 形式，并集成了其他的先进检测技术（如 decoupled head、SimOTA 等），取得了当时的 SOTA 性能。类似于 YOLOv5、YOLOv4-Tiny，YOLOX 也提供了多个尺度版本的模型，Nano/Tiny/s/m/l/x，而且该方法的 ONNX、TensorRT、NCNN、OpenVino 推理模型均已开源。

### Input

YOLOX 摒弃了在 YOLOv1-v5 使用的预训练，并使用了 Mosaic 和 Mixup 高阶数据增强技术。

Mixup 最初应用于分类任务，它将两张图片通过设定的融合系数进行融合，两个图片的 label 也对应融合。由于 Mosaic 和 Mixup 数据增强技术已足够强大，在这种情况下使用 ImageNet 数据集进行预训练已经不能带来有效的增益，故 YOLOX 摒弃了预训练逻辑，并从头开始训练。

### Backbone

YOLOX 沿用了 YOLOv3 的 backbone 结构。

### Neck

YOLOX 沿用了 YOLOv3 的 neck 结构，并增加了一个 SPP 模块，即 SPP+FPN。

### Head

YOLOX 在 YOLOv3 的 head 基础上提出了 decoupled head，同时结合 anchor-free 思想和 SimOTA 正负样本分配策略进行损失函数的优化。

YOLOX 使用了三个 decoupled head（解耦头），分别聚焦 cls（分类信息）、reg（检测框信息）、IoU（置信度信息）。比起 decoupled head，常规的检测头在特征的表达与学习能力上有所欠缺，并且 decoupled head 能加快模型的收敛速度。

对于正负样本分配，YOLOX 设计了样本初筛+SimOTA 的分配策略。在样本初筛中，有两种方法来筛选正样本：

1. 根据中心点判断：找到中心点落在 ground-truth 框中的所有 b-box
2. 根据检测框判断：以 ground-truth 中心点作为基准，绘制一个边长为 $n$ 的正方形，找到中心点落在这个正方形中的所有 b-box

经过样本初筛后，再使用 SimOTA 进行精细化筛选。 

### Others

**decoupled head**

在目标检测中，分类任务与回归任务的冲突是一种常见问题。因此，分类与定位头的解耦已被广泛应用到一阶段、两阶段的目标检测中。然而 YOLOv3/v4/v5 都没有对检测头进行解耦，作者通过实验发现，解耦检测头能让模型收敛更快。 

解耦头，意味着检测头会多一个分支结构，所以参数量会增加，为了尽量少增加参数，作者在进入预测分支之前先用 $1*1$ 卷积层将特征通道数减少，然后再接分类分支和回归分支。具体来说，作者先采用 $1*1$ 卷积层将特征通道减少到 256，然后添加两个平行分支，每个分支由两个 $3*3$ 卷积层组成，分别用于分类和回归，并将 IoU 分支添加到回归分支中。  

**anchor-free**

Anchor-based 方法有两点弊端：

1. 需要对数据集的所有标注框进行聚类分析，以确定最佳的 anchor 集合，这会导致训练出来的模型使用场景及泛化性受限
2. 锚框设计增加了检测头的复杂性和预测框数量

无锚框机制显著减少了需要启发式调整的设计参数的数量和涉及的一些技巧（如锚框聚类、网格敏感），使检测器的训练和解码得到较大简化。将 anchor-based 调整为 anchor-free 较为简单，作者将每个位置的预测从 3 个（YOLOv3 的每个 grid cell 有 3 个 anchor）减少到 1 个，并让它们直接预测 4 个值（即网格左上角的两个偏移量，以及预测框的宽度和高度）。改成 anchor-free 后，作者参考 FCOS，将每个目标的中心定位正样本，并预定义一个尺度范围以便对每个目标指派 FPN 特征尺度。Anchor-free 使得模型参数和 GFLOPs 都得到了减少，推理速度得到了提升，AP 也得到了增加。

**multi positives**

一个 ground-truth 只能匹配一个正样本，这意味着模型容易忽略掉周边其他的高质量预测框，然而这类被忽略的高质量预测框能够产生有用的梯度，因此 YOLOX 提出在 ground-truth 中心点划定一个 $3*3$ 的区域用于匹配更多的正样本，这一改进不仅减少了训练期间正负样本的不平衡，还提高了模型的精度。

**SimOTA**

OTA 从全局角度分析标签分配，并将分配过程制定为最优运输（Optimal Transport, OT）问题，从而产生当前分配策略中的 SOTA 性能。然而，在实践中作者发现用 Sinkhorn-Knopp 算法求解 OT 问题带来了额外 25% 的训练时间，这对于训练来说是相当昂贵的。因此，作者将其简化为动态 top-k 策略，以获得近似解，并命名为 SimOTA。

YOLOv5 的正负样本分配策略是基于邻域匹配，并通过跨网格匹配增加正样本数量，从而加速网络收敛，但是该方法属于静态分配方法，并不会随着网络训练的过程而调整。YOLOX 使用的 SimOTA 能够动态分配正样本，进一步提高检测精度。而且相比 OTA 使用的 Sinkhorn-Knopp 算法会导致训练时间的加长，SimOTA 使用 top-k 近似策略来得到样本的最佳匹配，大大加快了训练速度。

**Cosine Annealing LR**

余弦退火学习率衰减策略（Cosine Annealing LR）使得学习率呈周期性变化，但我们通常取它的一个余弦周期来完成整个训练过程。

另外，固定步长衰减（Step LR）、多步长衰减（Multi Step LR）、指数衰减（Exponential LR）等都是经典实用的学习率衰减策略。

固定步长衰减在每隔一定的步长或者 epoch 对学习率进行相应衰减；而多步长衰减策略比起固定步长衰减则更加灵活，它可以在不同阶段使用不同强度和频率的衰减策略；指数衰减策略是使用指数逻辑对学习率进行衰减。

### Improve

由于 YOLOX 的 baseline 是 YOLOv3-SPP，因此与其作比较，改进如下：

1. **训练策略：** 作者在训练 YOLOv3-SPP 时，在 baseline 的基础上加入了一些策略，比如在训练过程中加入了 EMA（指数移动平均）权重更新技术，使用 Cosine 学习率下降，用 BCE loss 训练分类分支和 obj 分支，用 IoU loss 和 IoU-aware 分支联合优化训练回归分支，使用 SGD 优化器
2. **删掉预训练：** YOLOX 摒弃了预训练，因为在强数据增强的情况下，预训练已经无法带来有效增益
3. **strong augmentation：** 在 YOLOX 中，数据增强用了随机水平翻转、颜色抖动、马赛克、Mixup、Mosaic
4. **anchor-free：** YOLOX 摒弃了 Anchor-based 方法，而改用 Anchor-free 方式预测边界框
5. **multi positives：** 为了获得更多的高质量预测框，以提高模型性能，YOLOX 提出了多正样本策略
6. **decoupled head：** YOLOX 提出了 decoupled head，用于解耦检测头
7. **SimOTA：** YOLOX 提出了 SimOTA，用于动态标签分配
8. **NMS free：** 作者在 YOLOX 中尝试去掉 NMS，这样的改动会导致掉点，因此作者最终没有进行该操作，但可作为一个参考选项

### Insight

YOLOX 的成功验证了在 anchor-free 机制下引入解耦头和先进的标签分配策略的有效性，并给出了一些重要的启示：

1. 适度的归纳偏置有利于提升检测器性能，如解耦头引入了独立建模分类和回归的先验，SimOTA 则利用了中心先验
2. 从任务出发简化检测器结构大有可为，去除 anchor 机制不仅简化了流程，还能在提速的同时提升精度
3. 强数据增强是训练高精度检测器的法宝，但不同规模和场景的最佳策略仍需进一步探索

## YOLOv6

美团视觉智能部，美团官方技术博客，publication date 2022/06

YOLOv6 是由美团视觉智能部研发的目标检测算法，旨在通过一些组件的设计提供一个高效率和高精度的目标检测模型，特别适用于需要快速且准确检测的工业应用场景。此外，YOLOv6 还支持多种平台的部署，包括 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等，极大地简化了工程部署时的适配工作。  

### Input

YOLOv6 的输入与 YOLOv5 的基本一样。

### Backbone

YOLOv6 的主干网络是 EfficientRep，受到硬件感知神经网络设计思想的启发，美团基于 RepVGG Style 设计了可重参数化结构，并将其命名为 EfficientRep Backbone。这种结构在训练时具有多分支拓扑，而在部署时可以融合为单个 $3*3$ 卷积层，有效利用计算密集型硬件的计算能力，如 GPU。

与 YOLOv5 的 backbone 相比，YOLOv6 的 backbone 不但能够高效利用硬件算力，而且还具有较强的表征能力。YOLOv6 在 backbone 中将 stride=2 的普通 Conv 层替换成了 stride=2 的 RepConv 层。同时，将原始的 CSPBlock 都重新设计为 RepBlock，其中 RepBlock 的第一个 RepConv 会做 channel 维度的变换和对齐。另外，YOLOv6 还将原始的 SPPF 优化设计为更加高效的 SimSPPF。 

### Neck

YOLOv6 的颈部网络是 Rep-PAN，Rep-PAN 基于 PAN（Path Aggregation Network）拓扑方式，用 RepBlock 替换了 YOLOv5 中使用的 CSPBlock，同时对整体 Neck 中的算子进行了调整。Rep-PAN 的设计旨在硬件上达到高效推理的同时，保持较好的多尺度特征融合能力。 

### Head

YOLOv6 的头部网络采用了更简洁有效的 Efficient Decoupled Head。YOLOv5 的检测头是通过分类和回归分支融合共享的方式实现的，而 YOLOX 的检测头则是将分类和回归分支进行解耦，同时增加了两个额外的 $3*3$ 卷积层，虽然提升了检测精度，但一定程度上也增加了网络延时。与它们相比，YOLOv6 对解耦头进行了精简设计，YOLOv6 的检测头通过分类和回归分支的解耦，同时综合考虑到相关算子表征能力和硬件上计算开销的平衡，采用 Hybrid Channels 策略重新设计了一个更高效的解耦头结构，在维持精度的同时降低了延时，缓解了解耦头中 $3*3$ 卷积层带来的额外延时开销。通过在 nano 尺寸模型上进行消融实验，对比相同通道数的解耦头结构，精度提升 0.2% AP 的同时，速度提升 6.8%。   

### Others

**Hardware-friendly 的主干网络设计**

YOLOv5/YOLOX 使用的 Backbone 和 Neck 都基于 CSPNet 搭建，采用了多分支的方式和残差结构。对于 GPU 等硬件来说，这种结构会一定程度上增加延时，同时减小内存带宽利用率。 

于是，作者基于硬件感知神经网络设计的思想，对 Backbone 和 Neck  进行了重新设计和优化。该思想基于硬件的特性（如处理器内核的计算特性、内存带宽等）、推理框架/编译框架的特点，以硬件和编译友好的结构作为设计原则，在网络构建时，综合考虑硬件计算能力、内存带宽、编译优化特性、网络表征能力等，进而获得又快又好的网络结构。对上述重新设计的两个检测部件，在 YOLOv6 中分别称为 EfficientRep Backbone 和 Rep-PAN Neck。

RepVGG Style 结构是一种在训练时具有多分支拓扑，而在实际部署时可以等效融合为单个 $3*3$ 卷积的一种可重参数化的结构。通过融合成的 $3*3$ 卷积结构，可以有效利用计算密集型硬件计算能力（比如 GPU），同时也可获得 GPU/CPU 上已经高度优化的 NVIDIA cuDNN 和 Intel MKL 编译框架的帮助。

实验表明，通过上述策略，YOLOv6 减少了在硬件上的延时，并显著提升了算法的精度，让检测网络更快更强。与 YOLOv5-nano 相比，YOLOv6-nano 在速度上提升了 21%，在精度上提升了 3.6%。

### Improve

YOLOv6 相较于 YOLOv5 作了如下改进：

1. **Backbone：** YOLOv6 设计了可重参数化、更高效的主干网络 EfficientRep Backbone
2. **Neck：** YOLOv6 设计了 Rep-PAN Neck，用 Rep 结构替代了 YOLOv5 neck 中的 CSP
3. **Head：** YOLOv6 设计了更简洁有效的 Efficient Decoupled Head，在维持精度的同时，进一步降低了一般解耦头带来的额外延时开销
4. **Anchor-free：** YOLOv6 采用了更简洁的 Anchor-free 检测方法
5. **SimOTA：** YOLOv6 引入了 SimOTA 标签分配策略
6. **SIoU：** YOLOv6 引入了 SIoU 边界框回归损失 

在训练策略上，作者采用 Anchor-free 无锚范式，同时辅以 SimOTA 标签分配策略以及 SIoU 边界框回归损失来进一步提高检测精度。

YOLOv6 进行了很多蒸馏方向上的尝试，比如 Self-distillation，Reparameterizing Optimizer，使用 Channel-wise Distillation 进行量化感知训练等，以进一步加强模型的整体性能。 

### QA

**为什么要使用 Anchor-free 无锚范式？**
答：YOLOv6 采用了更简洁的 Anchor-free 检测方法。由于 Anchor-based 检测器需要在训练之前进行聚类分析以确定最佳的 Anchor 集合，这会在一定程度上增加检测器的复杂度。同时，在一些边缘端的应用中，需要在硬件之间搬运大量检测结果的步骤也会带来额外的延时。Anchor-free 无锚范式因其泛化能力强，解码逻辑更简单，因而在近几年中应用比较广泛。经过对 Anchor-free 的实验调研发现，相较于 Anchor-based 检测器的复杂度而带来的额外延时，Anchor-free 检测器在速度上能够有 51% 的提升。

**为什么要使用 SimOTA 标签分配策略？**
答：为了获得更多高质量的正样本，YOLOv6 引入了 SimOTA 算法动态分配正样本，进一步提高检测精度。YOLOv5 的标签分配策略是基于 Shape 匹配，并通过跨网格匹配策略增加正样本数量，从而使得网络快速收敛，但是该方法属于静态分配方法，并不会随着网络训练的过程而调整。
近年来，也出现不少基于动态标签分配的方法，此类方法会根据训练过程中的网络输出来分配正样本，从而可以产生更多高质量的正样本，继而又促进网络的正向优化。例如，OTA 通过将样本匹配建模成最佳传输问题，求得全局信息下的最佳样本匹配策略以提升精度，但 OTA 由于使用了 Sinkhorn-Knopp 算法导致训练时间加长，而 SimOTA 算法使用 Top-K 近似策略来得到样本最佳匹配，大大加快了训练速度，因此 YOLOv6 采用了 SimOTA 动态分配策略。 

**为什么要使用 SIoU 边界框回归损失？**
答：为了进一步提升回归精度，YOLOv6 采用了 SIoU 边界框回归损失函数来监督网络的学习。目标检测网络的训练一般至少需要定义两个损失函数：分类损失和边界框回归损失，而损失函数的定义往往对检测精度以及训练速度产生较大的影响。
近年来，常用的边界框回归损失包括 IoU、GIoU、DIoU、CIoU loss 等等，这些损失函数通过考虑预测框与目标框之间的重叠程度、中心点距离、宽高比等因素来衡量两者之间的差距，从而指导网络最小化损失以提升回归精度，但是这些方法都没有考虑到预测框与目标框之间方向的匹配性。SIoU 损失函数通过引入了所需回归之间的向量角度，重新定义了距离损失，有效降低了回归的自由度，加快网络收敛，进一步提升了回归精度。通过在 YOLOv6s 上采用 SIoU loss 进行实验，对比 CIoU loss，平均检测精度提升了 0.3% AP。

## YOLOv6 2.0

美团视觉智能部，YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications, publication date 2022/09

美团视觉智能部在 2022.09.05 发布了 YOLOv6 2.0 版本，本次更新对轻量级网络进行了全面升级，量化版模型 YOLOv6-S 达到了 869 FPS，同时还推出了综合性能优异的中大型网络（YOLOv6-M/L），丰富了 YOLOv6 网络系列。其中，YOLOv6-M/L 在 COCO 上检测精度（AP）分别达到 49.5%/52.5%，在 T4 卡上推理速度分别可达 233/121 FPS（batch size=32）。

YOLOv6 系列模型的检测指标均在训练 300 epoch 且不使用预训练模型或额外检测数据集下获得，速度指标均在 T4 TRT7.2 环境下测试得到。

本次版本升级，获得了性能更强的全系列模型，主要有以下更新：

1. 针对中大型模型（YOLOv6-M/L），设计了新主干网络 CSPStackRep，它在综合性能上比上一版的 Single Path 结构更具优势
2. 针对不同网络，系统性地验证了各种最新策略/算法的优劣，综合精度和速度，为每类网络选择合适的方案。同时将模型整体训练时间减少了 50%，极大地提升了模型的训练效率
3. 引入自蒸馏思想并设计了新的学习策略，大幅提升了 YOLOv6-M/L 的模型精度
4. 通过训练时 Early Stop 强数据增强及推理时图像 Resize 优化策略，修复了前期版本中输入尺寸对齐到 $640*640$ 后精度损失的问题，提升了现有模型的实际部署精度

对比业界其他 YOLO 系列算法，YOLOv6 在所有系列均具有一定的优势：

- YOLOv6-M 在 COCO val 上取得了 49.5% 的精度，在 T4 显卡上使用 TRT FP16 batchsize=32 进行推理，可达到 233 FPS 的性能
- YOLOv6-L 在 COCO val 上取得了 52.5% 的精度，在 T4 显卡上使用 TRT FP16 batchsize=32 进行推理，可达到 121 FPS 的性能
- 同时，YOLOv6-N/S 模型在保持同等推理速度情况下，大幅提升了精度指标，训练 400 epoch 的条件下，N 网络从 35.0% 提升至 36.3%，S 网络从 43.1% 提升至 43.8%

本次发布还集成了专门针对 YOLOv6 的量化方案，对重参数化系列模型的量化也有参考意义。该方案借鉴 RepOptimizer 在梯度更新时做重参数化，解决了多支路动态范围过大导致难以量化的问题，用 RepOptimizer 训练的 YOLOv6 模型可以直接使用训练后量化（Post-training Quantization, PTQ），而不产生过大的精度损失。

在这一基础上，作者分析了各层的量化敏感性，将部分敏感层以更高精度运算，进一步提升了模型的精度。另外，同时发布了针对 2.0 版本的基于逐通道蒸馏的量化感知训练方案（Quantization-aware Training, QAT），并结合图优化，YOLOv6-S 2.0 版本的量化性能可达到 43.3 mAP 和 869 FPS（batch size=32）。

YOLOv6 支持检测模型训练、评估、预测以及模型量化、蒸馏等全链路开发流程，同时支持 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等不同平台的部署，极大简化工程部署时的适配工作。  

## YOLOv6 3.0

美团视觉智能部，YOLOv6 v3.0: A Full-Scale Reloading, publication date 2023/01

美团视觉智能部在 2023.01.06 发布了 YOLOv6 3.0 版本，再一次将目标检测的综合性能推向新高。本次更新除了对 YOLOv6-N/S/M/L 模型进行全系列升级之外，还推出了大分辨率 P6 模型。其中，YOLOv6-L6 检测精度达到 57.2% AP，在 T4 卡上推理速度可达 29 FPS，超越 YOLOv7-E6E，取得当前实时目标检测榜单 SOTA。

本次更新主要在 Neck 网络设计、训练和蒸馏策略等方面进行了创新和优化：

- 设计了表征能力更强的可重参化双向融合 PAN（RepBi-PAN）Neck 网络
- 提出了全新的锚点辅助训练（Anchor-Aided Training）策略
- 提出了解耦定位蒸馏（Decoupled Location Distillation）策略以提升小模型的性能

### 关键技术介绍

**表征能力更强的 RepBi-PAN Neck 网络**

有效的多尺度特征融合网络对目标检测的效果尤为关键。特征金字塔网络（FPN）通过自上而下的路径融合来自主干网络不同 Stage 的输出特征，以弥补网络学习过程中目标位置信息的损失。鉴于单向信息流传输的局限性，PANet 在 FPN 之上添加了一个额外的自底向上路径。BiFPN 为不同的输入特征引入了可学习的权重，并简化了 PAN 以实现更好的性能和更高的效率。PRB-FPN 通过具有双向融合的并行残差 FPN 结构来保留高质量的特征，以进行准确定位。

受到上述工作的启发，作者提出了一个表征能力更强的可重参化双向融合 PAN（RepBi-PAN）Neck 网络。一般而言，主干网络浅层特征分辨率高，具有丰富的空间信息，有利于目标检测中的定位任务。为了聚合浅层特征，常见的做法是在 FPN 中增加 P2 融合层以及一个额外的检测头，但这往往会带来较大的计算成本。

为了实现更好的精度和时延权衡，作者设计了一个双向联结（Birectional Concatenate, BiC）模块，在自上而下的传输路径中引入自底向上的信息流，使得浅层特征能以更高效的方式参与多尺度特征融合，进一步增强融合特征的表达能力。此模块能够帮助保留更准确的定位信号，这对于小物体的定位具有重要意义。

此外，作者对上一版本的 SimSPPF 模块进行了特征增强优化，以丰富特征图的表示能力。作者发现 YOLOv7 使用的 SPPCSPC 模块能够提升检测精度，但对网络推理速度的影响较大。于是作者对其进行了简化设计，在检测精度影响不大的情况下，大大提升了推理效率。同时，作者引入了可重参数化思想并对 Neck 网络的通道宽度和深度进行了相应的调整。

在 YOLOv6-S/L 模型上，仅在 PAN 网络自上而下的传输路径中引入 BiC 模块后，对推理速度影响保持在 4% 的情况下，检测精度分别提升 0.6% 和 0.4% AP。当作者尝试额外地在自底向上的信息流中将常规联结替换成 BiC 模块时，反而没有获得进一步的正向增益，因此作者仅在自上而下的路径中应用 BiC 模块。与此同时，作者还注意到，BiC 模块能够为小目标的检测精度带来 1.8% AP 的提升。

作者尝试在主干网络 C3、C4 和 C5 的输出特征后分别采用 SimSPPF 模块以加强特征的聚合表达，但从实验结果来看，重复使用 SimSPPF 模块虽然增加了计算量，但并没有带来检测精度的进一步提升。 经简化设计的 SPPCSPC 模块对比 SimSPPF 模块在 YOLOv6-N/S 模型上分别提升了 1.6% 和 0.3% AP，但推理速度 FPS 降低约 10%。而将 SimSPPF 模块替换为优化后的 SimCSPSPPF 模块后，在 YOLOv6-N/S/M 模型上分别取得了 1.1%/0.4%/0.1% 的精度增益，同时推理速度对比 SimSPPCSPC 模块有较大的提升。因此，为了更好的精度-效率权衡，在 YOLOv6-N/S 上采用 SimCSPSPPF 模块，而在 YOLOv6-M/L 上采用 SimSPPF 模块。

**全新的锚点辅助训练（Anchor-Aided Training）策略**

基于深度学习的目标检测技术从学习范式上主要可分为 Anchor-based 和 Anchor-free 两大类，这两类方法在不同尺度的目标检测上分别存在不同的优势。作者使用 YOLOv6-N 作为基线，对 Anchor-based 和 Anchor-free 范式的异同点进行了相关的实验和分析，从实验结果了解到，当 YOLOv6-N 分别采用 Anchor-based 和 Anchor-free 训练范式时，模型的整体 mAP 几乎接近，但采用 Anchor-based 的模型在小、中、大目标上的 AP 指标会更高。因此可以得出结论：相比于 Anchor-free 范式，基于 Anchor-based 的模型存在额外的性能增益。

作者发现，YOLOv6 使用 TAL 进行标签分配时，其模型精度的稳定性与是否采用 ATSS 预热有较大关系。当不使用 ATSS 预热时，YOLOv6-N 的模型精度最高可达 35.9% mAP，但当使用 ATSS 预热时，模型精度最高却只能达到 35.7% mAP。从实验结果可以分析得出，ATSS 的预热过程利用了 Anchor-based 的预设信息，进而达到稳定模型训练的目的，但也会在一定程度上限制网络的峰值能力，因此并不是一种最优的选择。

受到上述工作的启发，作者提出了基于锚点辅助训练（Anchor-Aided Training, AAT）策略。在网络训练过程中，同时融合 Anchor-based 和 Anchor-free 的两种训练范式，并对全阶段网络进行映射及优化，最终实现了 Anchor 的统一，充分发挥了结合不同 Anchor 网络的各自优势，从而进一步提升了模型检测精度。具体来说：

- 一方面，作者会在网络的分类头和回归头上分别添加 Anchor-based 辅助分支，在训练阶段，该分支与 Anchor-free 分支分别进行独立的 Loss 计算，之后会对 Loss 进行相加，各自反向传播进行网络的优化。通过 Anchor-based 辅助分支，为网络训练引入额外的内嵌指导信息，并与 Anchor-free 分支的信息进行整合，从而达到对结合不同 Anchor 网络的全方位融合的目的，进一步挖掘网络自身的潜力，充分发挥其效能
- 另一方面，在网络标签匹配的过程中引入了同特征点密集采样的机制。通过扩大每次样本匹配过程中所选取候选框的范围，增加候选框中正样本的数量，并且对同一特征点重复投放采样点，进一步提升在训练过程中候选框的质量。与此同时，在网络的每一层中还会搭配原始的 Anchor-free 分支，进一步提升候选框的多样性

除此之外，作者还提出灵活配置的训练策略，仅在训练过程中引入额外的辅助分支，在测试过程中不予使用。最终在不增加推理时间的情况下，提升网络精度，无痛涨点。

YOLOv6-S 模型采用 AAT 策略后有 0.3% 的精度增益，而在 YOLOv6-M/L 模型上分别带来了 0.5% 的精度增益。值得注意的是，YOLOv6-N/S/M 在小目标检测的精度指标上得到了显著增强。

**无痛涨点的 DLD 解耦定位蒸馏策略**

在目标检测的蒸馏任务中，LD 通过引入 DFL 分支，从而达到了在网络中对定位信息蒸馏的目的，使分类和定位信息得以同步回传，弥补了 Logit Mimicking 方法无法使用定位蒸馏信息的不足。但是，DFL 分支的添加，对于小模型速度的影响是很明显的。添加了 DFL 分支后，YOLOv6-N 的速度下降了 16.7%，YOLOv6-S 的速度下降了 5.2%。而在实际的工业应用当中，对于小模型速度的要求往往很高。因此，目前的蒸馏策略并不适合于工业落地。

针对这个问题，作者提出了基于解耦检测任务和蒸馏任务的 DLD（Decoupled Location Distillation）算法。DLD 算法会在网络每一层的回归头上分别添加额外的强化回归分支，在训练阶段，该分支同样会参与 IoU 损失的计算，并将其累加到最终的 Loss 中。

通过增加额外的强化回归分支，可以对网络添加更多的额外约束，从而对网络进行更全面细致的优化。并且，DLD 算法在对强化回归分支进行训练时，引入了分支蒸馏学习策略，该策略仅使用 DFL 分支参与网络标签分配，并将标签分配的结果投入到强化回归分支进行引导学习，从而参与强化回归分支的损失函数计算和反向传播优化。为什么这样做：

- 一方面，DFL 分支的精度更高，在整个训练周期可以起到对强化分支蒸馏的作用，进一步提升强化分支的精度
- 另一方面，通过分支蒸馏进行的引导学习，可以进一步将 DFL 分支的效果传递给强化回归分支，为之后的灵活配置起到铺垫作用

除此之外，DLD 算法同样搭配了灵活配置的训练策略，在训练过程中采用双回归分支结构，对网络进行了更全面细致的优化，进一步对齐双分支的回归能力。在测试过程中，移除掉了冗余的 DFL 分支，仅保留强化回归分支，在简化网络的同时保持了网络精度，最终实现了对目标检测任务可无痛涨点的 DLD 蒸馏算法。DLD 蒸馏策略可在不影响推理效率的前提下，提升小模型的检测精度，实现无痛涨点。   

## YOLOv7

Chien-Yao Wang, YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors, publication date 2022/07

YOLOv7 的作者团队与 YOLOv4 的相同，YOLOv7（7 月）紧随 YOLOv6（6 月）发布。

近年来，模型结构重参化和动态标签分配已成为网络训练和目标检测中的重要优化方向。在 YOLOv7 中，作者提出了一些已经发现的问题，例如:

- 对于模型结构重参化，用梯度传播路径的概念分析了适用于不同网络中各层结构重参化策略，提出了规划的模型结构重参化
- 当使用动态标签分配策略时，多输出层的模型在训练时会产生新的问题，比如怎样才能为不同分支更好的输出分配动态目标。针对这个问题，作者提出了一种新的标签分配方法，称为 coarse-to-fine（由粗到细）引导标签分配策略

YOLOv7 的主要贡献如下：

- 设计了几种可训练的 bag-of-freebies，使实时检测器可以在不提高推理成本的情况下大大提高检测精度
- 对于目标检测的发展，作者发现了两个新的问题，即模块重参化如何高效替代原始模块，以及动态标签分配策略如何处理好不同输出层的分配。作者针对这两个问题提出了相应方法进行解决
- 作者为实时检测器提出了“扩展”和“复合缩放”（extend and compound scaling）方法，可以更加高效地利用参数和计算量。作者提出的方法可以有效地减少实时检测器 50% 的参数，并且具备更快的推理速度和更高的检测精度。（这个其实和 YOLOv5 或 Scale YOLOv4 的 baseline 使用不同规格分化成几种模型类似，既可以是 width 和 depth 的缩放，也可以是 module 的缩放）

YOLOv7 提到当前目标检测主要的优化方向，有：更快更强的网络架构；更有效的特征集成方法；更准确的检测方法；更精确的损失函数；更有效的标签分配方法；更有效的训练方法。

对于当时的目标检测器，YOLOv7 在 5 FPS 到 160 FPS 范围内的速度和准确度都超过了所有已知的目标检测器，并且在 GPU V100 上 30 FPS 或更高的所有已知实时目标检测器中具有最高的准确度 56.8% AP。YOLOv7-E6 目标检测器（56 FPS, 55.9% AP）比 Transformer-based 的检测器在速度和准确度方面都要高。   

### Input

YOLOv7 的输入沿用了 YOLOv5 的整体逻辑，没有引入什么新的 trick。

### Backbone

YOLOv7 的 backbone 在 YOLOv5 基础上，设计了 E-ELAN 和 MPConv 结构。E-ELAN 结构使用 expand、shuffle、merge cardinality 等策略，以实现在不破坏原梯度路径的情况下，提高网络的学习能力。MPConv 结构由常规卷积和 Maxpool 双路径组成，增强了模型对特征的提取融合能力。不论是 E-ELAN 还是 MPConv，都将特征重用逻辑演绎到了较高水准，让人眼前一亮。

**CSPDarknet53**

YOLOv7 的 backbone 是其网络架构的核心部分，主要负责提取图像的特征。在 YOLOv7 中，backbone 采用了 CSPDarknet53 结构，该结构在 YOLOv5 中已经被广泛使用。CSPDarknet53 结构通过引入 CSP（Cross Stage Partial）模块，增强了网络的特征提取能力，同时减少了计算量。

CSP 模块的设计思路是将特征图分为两个部分，一部分进行下采样操作，另一部分则进行上采样操作，然后再将两部分特征图进行拼接。这种设计方式可以在不增加计算量的前提下，提高网络的特征提取能力。在 YOLOv7 中，CSPDarknet53 结构被进一步优化，以提高网络的性能。

**CBS**

在 YOLOv7 中，除了 CSPDarknet53 结构外，还有两个重要的模块：CBS 模块和 CBM 模块。这两个模块都是用于增强网络的特征提取能力。

CBS（Convolutional Block with Silu Activation）模块是 YOLOv7 中引入的一种新型卷积块。该模块采用了 Silu 激活函数，该函数是 Swish 激活函数的变体，具有更好的非线性表达能力。在 CBS 模块中，卷积操作采用了分组卷积（Group Convolution）的方式，以减少计算量。同时，为了进一步提高网络的特征提取能力，CBS 模块还引入了残差连接（Residual  Connection）和注意力机制（Attention Mechanism）。

**CBM**

CBM（Convolutional Block with Mish  Activation）模块与 CBS 模块类似，也采用了分组卷积和残差连接的方式。不同的是，CBM 模块采用了 Mish 激活函数，该函数在特征提取方面表现出色。此外，CBM 模块还引入了空间金字塔池化（Spatial Pyramid Pooling）技术，以提高网络对不同尺度目标的检测能力。

### Neck

YOLOv7 的 neck 由 SPPCSPC 模块和优化的 PAN 模块组成。

SPPCSPC 在 SPP 基础上增加了 concat 操作，将经过 SPP 得到的特征图与 SPP 模块之前的特征图进行融合，进一步增强了特征表达能力。

YOLOv7 中的 PAN 模块在原 PAN 基础上引入了 E-ELAN 结构，进一步提升模型学习能力。

### Head

YOLOv7 沿用了 YOLOv5 的损失函数，引入了 RepVGG Style 来改造 YOLOv5 的 head，并使用了辅助头（auxiliary head）训练及相应的正负样本分配策略。

RepVGG Style 在训练过程中可通过多路分支提升性能，在推理过程中可通过结构重参化加快推理时间。有人对 RepVGG Style 思想进行了迁移性实验，发现 RepVGG Style 在不同模型中的兼容性并不是很强，往往需要针对当前的模型和场景进行大量调参才能展现一定效果。

YOLOv7 在 head 中引入了辅助头来辅助训练，辅助头将对模型的训练进行深度监督。将辅助头和检测头的损失进行融合，相当于在网络高层进行局部的模型 ensemble 操作，提升了模型的整体性能。

YOLOv7 的正负样本分配策略是围绕检测头与辅助头进行设计的，主要就是将 YOLOv5 和 YOLOX 的分配策略结合在了一起，即邻域匹配+SimOTA。具体实现流程如下：

1. 使用 YOLOv5 中基于邻域的正负样本分配策略来分配正样本
2. 计算每个样本对每个 ground-truth 的 cls+reg loss（loss aware）
3. 使用每个 ground-truth 的预测样本确定它需要分配到的正样本数（dynamic k）
4. 为每个 ground-truth 取 loss 最小的前 dynamic k 个样本作为正样本
5. 人工去掉同一个样本被分配到多个 ground-truth 的正样本情况（全局信息）

从实现流程来看，邻域匹配+SimOTA 的结合策略其实就是将 SimOTA 中的第一步“使用中心先验”替换成了 YOLOv5 中的邻域匹配策略。

YOLOv7 的正负样本分配策略相较于 YOLOv5，加入了 loss aware，能够实现样本的精筛；而相较于 YOLOX，能够提供更精确的先验知识。

检测头与辅助头中的正负样本分配策略：

- 检测头和辅助头使用一样的正负样本分配策略，通过让浅层的辅助头学习到检测头已经获得的特征，让检测头更能专注于学习尚未学习到的剩余特征。
- 在使用检测头和辅助头一起优化模型的时候，辅助头的正样本是较为“粗糙的“，其主要是通过放宽正样本分配过程的约束来获得更多的正样本。检测头中的一个 anchor 如果匹配上 ground-truth，则分配 3 个正样本，而同样的情况下辅助头分配 5 个。检测头中将 top 10 个样本的 IoU 求和取整，而辅助头中取 top 20。辅助头的学习能力不如检测头强，为了避免丢失需要学习的信息，需要重点优化辅助头的召回率。而检测头可以从高 recall 的结果中筛选出高精度的结果作为最终输出。检测头和辅助头的损失函数权重设置为 $4:1$。  

### Others

**高效的聚合网络**

在大多数关于设计高效网络的论文中，主要考虑的因素是参数量、计算量和计算密度。但从内存访存的角度出发，还可以分析输入/输出信道比、架构的分支数和元素级操作对网络推理速度的影响。在执行模型缩放时还需考虑激活函数，即更多地考虑卷积层输出张量中的元素数量。

YOLOv7 中使用的 CSPVoVNet 是 VoVNet 的一个变体，它不仅考虑到了上述提到的模型设计问题，还分析了梯度在模型中的流动路径，通过梯度路径使不同层的权重能够学习到更加多样化的特征。不管是训练阶段还是推理阶段，梯度分析方法都能起到不错的效果，尤其是在推理方面，能够使推理速度更快、模型更准确。

通过控制最短最长梯度路径，可以设计更高效的网络，从而让更深的网络可以更加高效地进行学习和收敛。基于以上考量设计了 ELAN 结构。

无论梯度路径长度和大规模 ELAN 中计算块的堆叠数量如何，网络都能够达到稳定状态，但倘若继续这样一直堆叠这些计算块，反而可能会破坏这种稳定的状态，从而导致参数利用率的降低。因此，在 YOLOv7 中，作者提出了基于 ELAN 的扩展版本 E-ELAN，它采用 expand、shuffle、merge cardinality 结构，实现了在不破坏原始梯度路径的情况下，提高网络的学习能力。

在体系结构方面，E-ELAN 只改变了计算模块中的结构，而过渡层的结构则完全不变。作者的策略是利用分组卷积来扩展计算模块的通道和基数，将相同的 group parameter 和 channel  multiplier 用于计算每一层中的所有模块。然后将每个模块计算出的特征图根据设置的分组数打乱成 G 组，最后将它们连接在一起。此时，每一组特征图中的通道数将与原始体系结构中的通道数相同。最后，作者添加了 G 组特征来 merge cardinality。除了维护原始的 ELAN 设计架构外，E-ELAN 还可以指导不同的分组模块来学习更多样化的特性。

**卷积重参化（bag-of-freebies）**

重参化技术是模型在推理时将多个模块合并成一个模块的方法，可以看作是一种集成技术（model ensemble），可以将其分为模块级集成和模型级集成两类。对于模型级重新参数化有两种常见的操作:

- 一种是用不同的训练数据训练多个相同的模型，然后对多个训练模型的权重进行平均
- 一种是对不同迭代次数下的模型权重进行加权平均

模块重参化是近年来一个比较流行的研究课题。这种方法在训练过程中将一个整体模块分割为多个相同或不同的模块分支，但在推理过程中将多个分支模块集成到一个完全等价的模块中。然而，并不是所有提出的重参化模块都可以完美地应用于不同的架构。考虑到这一点，YOLOv7 作者开发了新的重参化模块，并为各种架构设计了相关的应用程序策略。

尽管 RepConv 在 VGG 上取得了优异的性能，但将它直接应用于 ResNet、DenseNet 或其他网络架构时，它的精度会显著降低。作者使用梯度传播路径来分析不同的重参化模块应该和哪些网络搭配使用。RepConv 结合了 $3*3$ 卷积、$1*1$ 卷积和一个 identity 连接，通过分析 RepConv 与不同架构的组合以及产生的性能，作者发现 RepConv 中的 identity 破坏了 ResNet 中的残差连接和 DenseNet 中的跨层连接，这为不同的特征图提供了更多的梯度多样性。因此作者认为，在同时使用重参化卷积与残差连接或跨层连接时，不应该存在 identity 连接，而且作者还分析重参数化的卷积应该如何与不同的网络结构相结合以及设计了不同的重参数化的卷积。基于上述原因，作者使用了没有 identity 连接的 RepConv 结构。

**基于 concat 的模型缩放（bag-of-freebies）**

模型缩放是指通过调整模型的大小来生成不同尺度的模型，使其适用于不同的计算设备，用于满足不同场景下的推理需求。模型缩放方法通常包括不同的缩放因子，如:

- input size（输入图像大小）
- depth（网络层数）
- width（特征图通道数/卷积核数）
- stage（特征金字塔数）

模型通过控制上述参数，在网络的参数量、计算量、推理速度和精度方面能够实现很好的权衡。网络架构搜索（NAS）也是目前常用的模型缩放方法之一。其实这里的缩放和 Scale YOLOv4、YOLOv5 差不多，Scale YOLOv4 是通过调整模型阶段数进行缩放，而 YOLOv5 是通过控制它的深度和宽度进行模型的缩放。

作者还发现，模型使用了 concat 时，不能单独地分析缩放因子的影响，还必须结合通道数的变化一起分析，因为在这过程中会导致输入通道和输出通道的比例发生变化，从而导致模型的硬件使用率降低。所以，该团队提出了一种复合缩放方法，这样不仅可以保持模型在初始设计时的特性，还可以保持模型性能最佳时的结构。这种方法就是在缩放一个计算块的深度因子时，还必须结合这个块的输出通道的变化进行计算，在过渡层用相同的变化量进行宽度因子缩放，就可以让模型在不改变初始设计时的特性的同时保持更优的结构。  

**辅助训练（bag-of-freebies）**

深度监督是一种常用于训练深度网络的技术，其主要概念是在网络的中间层增加额外的辅助头，以及以辅助损失为指导的浅层网络权重。即使对于像 ResNet 和 DenseNet 这样收敛效果好的网络结构，深度监督仍然可以显著提高模型在许多任务上的性能（按笔者理解可以当成是深层局部网络的 ensemble，最后将辅助头和检测头的权重做融合）。

**标签分配（bag-of-freebies）**

在过去的深度网络的训练中，标签分配通常直接指的是 ground truth，并根据给定的规则生成 hard label（未经过 softmax）。然而近年来，以目标检测为例，研究者经常利用网络预测的质量分布结合 ground truth，使用一些计算和优化方法来生成可靠的软标签（soft label）。例如，YOLO 系列使用 bounding box 预测和 ground truth 的 IoU 作为软标签。在 YOLOv7 中，作者将网络预测结果与 ground truth 一起考虑后再分配软标签的机制称为“标签分配器”。无论辅助头或检测头，都需要对目标进行深度监督，那么该如何为辅助头和检测头合理分配软标签呢，这是作者需要考虑的问题。目前最常用的方法就是将辅助头和检测头分离，然后利用它们各自的预测结果和 ground truth 执行标签分配。YOLOv7 提出的方法是一种新的标签分配方法，通过检测头的预测来引导辅助头以及自身。换句话说，首先使用检测头的 prediction 作为指导，生成从粗到细的层次标签，分别用于辅助头和检测头的学习。

**Lead head guided label assigner：** 检测头引导“标签分配器”预测结果和 ground truth 进行计算，并通过优化生成软标签。这组软标签将作为辅助头和检测头的目标来训练模型，这样做的目的是使检测头具有较强的学习能力，由此产生的软标签更能代表源数据与目标之间的分布差异和相关性。此外，作者还可以将这种学习看作是一种广义上的余量学习，通过让较浅的辅助头直接学习检测头已经学习到的信息，检测头能更加专注于尚未学习到的残余信息。

**Coarse-to-fine lead head guided label assigner：** Coarse-to-fine 检测头使用到了自身的 prediction 和 ground truth 来生成软标签，引导标签进行分配。然而在这个过程中，作者生成了两组不同的软标签，即粗标签和细标签。其中细标签与检测头在标签分配器上生成的软标签相同，粗标签是通过降低正样本分配的约束，允许更多的网格作为正目标（参考 FastestDet 的 label assigner，不单单只把 gt 中心点所在的网格当成候选目标，还把附近的三个也算进去，增加正样本候选框的数量）。原因是一个辅助头的学习能力并不需要强大的检测头，为了避免丢失信息，作者将专注于优化样本召回的辅助头。对于检测头的输出，可以从查准率中过滤出高精度值的结果作为最终输出。

然而值得注意的是，如果粗标签的附加权重和细标签的附加权重差不多，那么在最终预测时就可能产生错误的先验结果。因此，为了使那些超粗的正网格影响更小，会在解码器中设置限制，来使超粗的正网格无法完美地产生软标签。通过上述机制，允许在学习过程中动态调整细标签和粗标签的重要性，使细标签始终优于粗标签。          

**其他可训练的 bag-of-freebies**

1. Batch Normalization：将 Batch Normalization 层直接连接到卷积层中，这样可以在推理时将批归一化的均值和方差直接整合到卷积层的偏差和权重中
2. YOLOR 中结合隐性知识和卷积特征图的加法和乘法方法：YOLOR 认为隐性知识可以在推理时通过预计算步骤被简化为向量，这个向量可以与前一个或后一个卷积层的偏差和权重相结合
3. EMA Model：EMA 是一种在 mean teacher 中使用的技术，作者使用 EMA 模型作为最终的推理模型。EMA 可以用来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关，这里可以起到平滑的作用。如果取 n 步的平均，就能使得模型更加得鲁棒 

**不同场景下的计算设备**

- CPU 边缘设备：对于这种场景，更多的是使用轻量级的 Backbone，如 MobileNet、ShuffleNet 或 GhostNet

- GPU 边缘设备：近年来，针对低功耗的移动端设备，也提出了不少目标检测算法，如 NanoDet。这些算法主要专注在高效的结构设计上，这样在保持推理精度的同时也可以提高推理的实时性
- 高性能 GPU 设备：这些设备大多是高算力 GPU、云端 GPU，对于这种场景，运行大模型也是没有什么压力的

### Improve

YOLOv7 相比于 YOLOv5，作了如下改进：

1. **Backbone：** YOLOv7 的 backbone 设计了 E-ELAN 和 MPConv 结构，用的 SiLU 激活函数
2. **Neck：** YOLOv7 使用了 SPPCSPC 和优化的 PAN 模块
3. **Head：** YOLOv7 引入了 RepVGG Style，使用辅助头进行辅助训练，使用邻域匹配+SimOTA 的正负样本分配策略
4. **删掉预训练：** YOLOv7 只在 MS COCO 数据集上从零开始训练，而不使用任何其他数据集或预训练的权重
5. **隐性知识：** YOLOv7 也使用了 YOLOv5 中提到的 EMA（Exponential Moving Average）策略，并引入了 YOLOR 中使用的隐性知识。YOLOR 中的隐式知识可以在推理阶段将计算值简化为向量，这个向量可以与前一个或后一个卷积层的偏差和权重相结合  

YOLOv7 沿用了 YOLOv5 的 Anchor-based 结构，并没有用 YOLOX、YOLOv6 中的 Anchor-free 和解耦头机制。 

## YOLOv8

YOLOv8 与 YOLOv5 的团队是同一个，是 Ultralytics 公司的开源项目，与 YOLOv5 一样，YOLOv8 同样没有论文，只有代码，代码于 2023.01.10 开源。Ultralytics 并没有直接将开源库命名为 YOLOv8，而是直接使用 ultralytics 这个词，原因是 Ultralytics 将这个库定位为可扩展的算法框架，而非某一个特定算法，其希望这个库不仅仅能够用于 YOLO 系列模型，而是能够支持非 YOLO 模型以及分类、分割、姿态估计等各类任务。

YOLOv8 是一个 SOTA 模型，在之前 YOLO 算法的基础上，进行了一系列改进。具体创新包括一个新的主干网络、一个新的 Anchor-free 检测头、一个新的损失函数。

### Input

YOLOv8 在模型训练过程中是自带在线数据增强的，也就是说它在模型训练时会对数据集实时地进行数据增强操作。YOLOv8 主要使用了颜色扰动、随机扰动、Mixup、Mosaic 等数据增强方式。

### Backbone

YOLOv8 的 backbone 沿用了 CSPDarknet53 的思想，将 YOLOv5 中的 C3 模块替换成了 C2f 模块，实现了进一步的轻量化，其余与 YOLOv5 的 backbone 大体一致。

C2f 模块借鉴了 YOLOv7 中的 ELAN 思想，通过并行更多的梯度流分支，实现在保证轻量化的同时获得更加丰富的梯度流信息，额外还增加了一个 Split 操作。

### Neck

YOLOv8 的 neck 由 SPPF+PAN 组成，其依旧使用了 PAN 思想，与 YOLOv5 相比，YOLOv8 将 PAN-FPN 上采样阶段中 CBS 的 $1*1$ 卷积结构删除了，同时将 C3 模块替换成了 C2f 模块。YOLOv8 依旧使用了 YOLOv5 等架构中的 SPPF，SPPF 与 SPP 的作用是一样的，但 SPPF 的速度更快。

### Head

YOLOv8 使用了 Decoupled Head 和 Anchor-free 机制，并删除了 objectness 分支，只有解耦的分类和回归分支，并且在回归分支中使用了 Distribution Focal Loss 中提出的积分形式表示法。DFL Loss（Distribution Focal Loss）的提出主要是为了解决 b-box 的表示不够灵活问题。在正负样本分配策略上，YOLOv8 采用了 ATL 策略。

### Others

**DFL Loss**

DFL Loss 的提出主要是为了解决 b-box 的表示不够灵活问题。传统的目标检测，尤其在复杂场景中，目标物体的真实框的框定其实是无法精确给出的（受到标注人的主观倾向或遮挡、模糊等造成的边界歧义及不确定性的影响）。传统的回归方法直接使预测值向一个离散的确定值（标签值 y）进行逼近，但实际上回归一个分布范围相比于逼近一个离散值会更符合事实。DFL Loss 就是基于这样的思想，将框的位置建模成一个 general distribution，让网络能够快速地聚焦于标签值 y 附近范围的位置分布。但如果分布过于随意，网络学习的效率可能不会很高，因为一个积分目标可能对应无穷多种分布模式。考虑到真实的分布通常不会距离标注的位置太远，DFL Loss 选择优化标签值 y 附近左右两个位置的概率，使得网络分布聚焦到标签值附近。

**ATL 标签分配策略**

YOLOv8 引入了 Task-Aligned Assigner 正负样本分配策略，该策略根据分类与回归的加权分数选择正样本。具体实现步骤如下：

1. 基于分类得分和预测框与 ground-truth 的 IoU，加权得到一个关联分类和回归的对齐分数 alignment_metrics
2. 计算 anchor 的中心点是否在当前 ground-truth 内，只有在当前 ground-truth 内的 anchor 才能作为正样本
3. 基于 alignment_metrics 选取 top k 作为正样本，其余作为负样本进行训练

### Improve

YOLOv8 相比于 YOLOv5，作了如下改进：

1. **Backbone：** YOLOv8 将 C3 模块替换成了 C2f 模块，实现了进一步的轻量化
2. **Neck：** YOLOv8 删除了 PAN 中的 $1*1$ 卷积结构，同时将 C3 模块替换成了 C2f 模块
3. **Head：** YOLOv8 使用了 Decoupled Head，并删除了 objectness 分支，只解耦了分类和回归分支 
4. **Anchor-free：** YOLOv8 与 YOLOX、YOLOv6 一样，摒弃了 Anchor-based 机制，而采用了 Anchor-free 方式
5. **损失函数改进：** YOLOv8 依旧采用 BCE Loss 作为分类损失，并采用 DFL Loss 和 CIoU Loss 作为回归损失，同时删除了 objectness 分支的损失计算
6. **TAL 标签分配策略：** YOLOv8 摒弃了以往的 IoU 匹配或单边比例的分配方式，而是使用了 TOOD 的 Task-Aligned Assigner 标签分配策略

## YOLOv9

Chien-Yao Wang, YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information, publication date 2024/02

YOLOv9 的作者团队与 YOLOv7 的作者团队是同一个。YOLOv9 通过研究数据传输时的信息丢失问题，提出了可编程梯度信息（PGI）和通用高效层聚合网络（GELAN）。PGI 可以为目标任务的计算目标函数提供完整的输入信息，从而获得可靠的梯度信息来更新网络权值。PGI 适用于从轻型到大型的各种模型，使从头开始训练的模型能够获得更好的结果。GELAN 是基于梯度路径规划的轻量级网络架构，与 SOTA 方法相比，GELAN 仅使用传统卷积算子即可实现更好的参数利用率。PGI 和 GELAN 的提出提高了参数利用率和模型性能。YOLOv9 被评价为新的 SOTA 实时目标检测器。

主要贡献：

1. YOLOv9 从可逆函数的角度理论分析了现有的深度神经网络架构，并通过这一过程成功解释了过去难以解释的许多现象；还基于这一分析设计了 PGI 和辅助可逆分支，并取得了优异的性能
2. 设计的 PGI 解决了深度监督只能用于极深神经网络架构的问题，因此允许新的轻量级架构真正应用于日常生活中
3. 设计的 GELAN 仅使用传统卷积就实现了比基于最先进技术的深度卷积设计更高的参数利用率，同时展现了轻巧、快速和准确的巨大优势
4. 结合所提出的 PGI 和 GELAN，YOLOv9 在 MS COCO 数据集上的目标检测性能在所有方面都大大超过了现有的实时目标检测器   

**YOLOv9 的提出背景**

近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，如 CNN、Transformer、Perceivers 和 Mambas。此外，一些研究人员试图开发更通用的目标函数，如损失函数、标签分配和辅助监督。这些研究都试图准确地找到输入任务和目标任务之间的映射。然而，大多数过去的方法都忽略了输入数据在前馈过程中可能具有不可忽略的信息损失量，这种信息丢失可能导致有偏差的梯度流，进而可能导致深度网络在目标和输入之间建立不正确的关联，导致训练的模型产生不正确的预测。

在深度网络中，输入数据在前馈过程中丢失信息的现象通常被称为信息瓶颈。目前，可以缓解这一现象的主要方法如下：

1. **使用可逆架构：** 这种方法主要使用重复的输入数据，并以显式的方式维护输入数据的信息
2. **Mask 建模：** 主要利用重建损失，采用隐式方法最大化的提取特征，保留输入信息
3. **引入深度监督概念：** 它使用没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射，以确保重要信息可以转移到更深的层 

然而，上述方法在训练过程和推理过程中都有不同的缺点。例如，可逆架构需要额外的层来组合重复馈送的输入数据，这将显著增加推理成本。此外，由于输入数据层到输出层不能有太深的路径，这种限制将使训练过程中难以对高阶语义信息进行建模。对于 mask 建模，其重建损失有时与目标损失相冲突。此外，大多数掩码机制也会产生与数据的不正确关联。对于深度监督机制来说，它会产生错误积累，如果浅层监督在训练过程中丢失信息，后续层将无法检索到所需的信息。上述现象在困难任务和小型模型中更为显著。

为了解决上述问题，作者提出了一个新的概念，即可编程梯度信息（PGI）。此外，作者用 GELAN 替代了 ELAN，同时兼顾了轻量级、推理速度和准确性。作者将所提出的 PGI 和 GELAN 相结合，设计了新一代 YOLO 系列目标检测框架，称之为 YOLOv9。 

**可编程梯度信息（PGI）**

为了缓解信息瓶颈这一问题，YOLOv9 提出了一种新的辅助监督框架，称为可编程梯度信息（PGI）。PGI 主要由三个部分组成：主分支、辅助可逆分支、多级辅助信息。

- 主分支：神经网络的核心部分，负责学习输入数据的主要特征
- 辅助可逆分支：为了处理神经网络加深带来的问题而设计的。网络加深会造成信息瓶颈，导致损失函数无法生成可靠的梯度
- 多级辅助信息：旨在处理深度监督带来的误差累积问题，特别是针对多个预测分支的架构和轻量级模型

PGI 的推理过程仅使用主分支，因此不需要任何额外的推理成本。辅助可逆分支和多级辅助信息用于训练阶段，以帮助解决神经网络加深带来的问题。

PGI 的设计旨在缓解信息瓶颈这一现象，其概念是通过辅助可逆分支生成可靠的梯度，使深层网络仍能保持执行目标任务的关键特征。辅助可逆分支的设计可以避免传统的集成多路径特征的深度监督过程可能导致的语义损失。换句话说，YOLOv9 对不同语义级别的梯度信息传播进行编程，从而获得最佳的训练结果。PGI 的可逆架构建立在辅助分支上，因此不需要额外的成本。由于 PGI 可以自由选择适合目标任务的损失函数，它也克服了掩模建模所遇到的问题。所提出的 PGI 机制可以应用于各种规模的深度神经网络，并且比仅适用于非常深度神经网络的深度监督机制更通用。

**通用高效层聚合网络（GELAN）**

通过结合采用梯度路径规划设计的两种神经网络架构 CSPNet 和 ELAN，YOLOv9 设计了兼顾轻量级、推理速度和准确性的通用高效层聚合网络，并将最初仅使用卷积层堆叠的 ELAN 的功能推广到了可以使用任何计算块的新架构。

YOLOv9 在 ELAN 的基础上设计了 Generalized ELAN（GELAN），即用 GELAN 替代了 YOLOv7 中的 ELAN 结构。GELAN 的设计同时考虑了参数的数量、计算复杂度、准确性和推理速度，这种设计允许用户为不同的推理设备任意选择合适的计算块。

与 PlainNet、ResNet、CSPNet 等网络架构相比，GELAN 能更好地保留输入数据的信息，为后续的目标函数计算提供更准确的梯度信息。

## YOLOv1~YOLOv8 的对比

| Model  | Anchor                                                 | Input                                                       | Backbone                                                     | Neck                  | Head                                                         |
| ------ | ------------------------------------------------------ | ----------------------------------------------------------- | ------------------------------------------------------------ | --------------------- | ------------------------------------------------------------ |
| YOLOv1 | 无锚框；每个网格预测 2 个边界框                        | resize($448*448*3$)                                         | 基于 GoogLeNet 修改的 CNN（$24*Conv+2*FC$）；Dropout；Leaky ReLU；Softmax | 无                    | IoU Loss；NMS                                                |
| YOLOv2 | 锚框；每个网格有 5 个 anchor box                       | resize($416*416*3$)；多尺度训练                             | Darknet-19（$19*Conv$）；BN；Leaky ReLU；Softmax             | 无                    | IoU Loss；NMS                                                |
| YOLOv3 | 锚框；三个分支，每个分支中的每个网格有 3 个 anchor box | resize($416*416*3$)                                         | Darknet-53（$52*Conv$）；BN；Leaky ReLU；Logistic            | FPN                   | IoU Loss；NMS；多标签分类（Logistic 替代 Softmax）           |
| YOLOv4 | 锚框                                                   | resize($608*608*3$)；CutMix+Mosaic；SAT                     | CSPDarknet53；CmBN；DropBlock；Mish                          | SPP+PAN               | CIoU Loss；DIoU NMS；Label Smoothing；正负样本分配策略（正例、负例、忽略样例） |
| YOLOv5 | 锚框                                                   | resize($608*608*3$)；Mosaic；自适应锚框计算；自适应图片缩放 | Focus+CSPDarknet53                                           | SPP/SPPF+PAN（CSP）   | GIoU Loss；DIoU NMS；邻域正负样本分配策略                    |
| YOLOX  | 无锚框                                                 | resize($608*608*3$)；无预训练；Mosaic+MixUp                 | Darknet-53                                                   | SPP+FPN               | CIoU Loss；DIoU NMS；Decoupled Head；SimOTA 标签分配策略     |
| YOLOv6 | 无锚框                                                 | resize($640*640*3$)                                         | EfficientRep                                                 | SimSPPF+Rep-PAN       | SIoU Loss；DIoU NMS；Efficient Decoupled Head；SimOTA 标签分配策略 |
| YOLOv7 | 锚框                                                   | resize($640*640*3$)                                         | Darknet-53（E-ELAN 替代了 CSP）；BN；SiLU                    | SPPCSPC+PAN（E-ELAN） | CIoU Loss；DIoU NMS；领域匹配+SimOTA                         |
| YOLOv8 | 无锚框                                                 | resize($640*640*3$)                                         | Darknet-53（C2f 替代了 C3）                                  | SPPF+PAN              | CIoU Loss；DFL Loss；DIoU NMS；Decoupled Head；TAL 标签分配策略 |